{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Socaio - Proof of Concept Pipeline\n",
    "\n",
    "**Simulate Public Opinion with a Crowd of LLMs**\n",
    "\n",
    "This notebook implements a proof-of-concept for the Socaio platform that provides instant, AI-driven focus groups by simulating how diverse audience segments will perceive, share, and react to communications.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Stage A**: User Prompt Intake\n",
    "2. **Stage B**: Audience Profiling (LLM meta-classifier)\n",
    "3. **Stage C**: Persona Selection\n",
    "4. **Stage D**: Response Simulation (Personified LLMs)\n",
    "5. **Stage E**: Insight Aggregation\n",
    "6. **Stage F**: Interactive Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Model configuration\n",
    "MODEL = \"gpt-4o\"\n",
    "MAX_TOKENS = 2000\n",
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AudienceSegment:\n",
    "    name: str\n",
    "    age: str\n",
    "    ethnicity: str\n",
    "    location: str\n",
    "    values: str\n",
    "    political_leaning: str\n",
    "    media_habits: str\n",
    "    confidence: float\n",
    "\n",
    "# M1: Enhanced Audience Profiling Metrics\n",
    "@dataclass\n",
    "class DemographicProfile:\n",
    "    age_band: str  # 5-year bands (18-22, 23-27, etc.)\n",
    "    gender_identity: str\n",
    "    ethnicity_omb: str  # OMB categories + \"prefer not to say\"\n",
    "    geography: Dict[str, str]  # country, state, urban_rural_flag\n",
    "    education_level: str\n",
    "    income_tier: str\n",
    "\n",
    "@dataclass\n",
    "class PsychographicProfile:\n",
    "    political_lean: float  # 7-point scale (-3 to +3)\n",
    "    schwartz_values: Dict[str, float]  # Values/cares using Schwartz value set\n",
    "    big5_personality: Dict[str, str]  # low/med/high for each trait\n",
    "    brand_affinity_cluster: str\n",
    "\n",
    "@dataclass\n",
    "class MediaHabits:\n",
    "    top_platforms: List[str]  # Top 3 platforms\n",
    "    preferred_content_format: str  # short video, long-form, text\n",
    "    daily_usage_hours: float\n",
    "\n",
    "@dataclass\n",
    "class Persona:\n",
    "    id: str\n",
    "    name: str\n",
    "    age: int\n",
    "    gender: str\n",
    "    ethnicity: str\n",
    "    location: str\n",
    "    occupation: str\n",
    "    values: List[str]\n",
    "    political_leaning: str\n",
    "    personality_traits: Dict[str, float]  # Big-5 traits\n",
    "    media_habits: List[str]\n",
    "    system_prompt: str\n",
    "    age_group: str = \"\"  # Added for grouping\n",
    "    location_type: str = \"\"  # Added for grouping (urban/suburban/rural)\n",
    "    # M1 Enhanced Metrics\n",
    "    demographic_profile: DemographicProfile = None\n",
    "    psychographic_profile: PsychographicProfile = None\n",
    "    media_profile: MediaHabits = None\n",
    "\n",
    "# M2: Enhanced Reaction Metrics\n",
    "@dataclass\n",
    "class EmotionVector:\n",
    "    joy: float\n",
    "    trust: float\n",
    "    fear: float\n",
    "    surprise: float\n",
    "    sadness: float\n",
    "    disgust: float\n",
    "    anger: float\n",
    "    anticipation: float\n",
    "\n",
    "@dataclass\n",
    "class PersonaReaction:\n",
    "    persona_id: str\n",
    "    # Core metrics\n",
    "    sentiment: float  # -5 to +5\n",
    "    share_likelihood: float  # 0-100%\n",
    "    emotional_triggers: List[str]\n",
    "    suggested_modifications: str\n",
    "    raw_response: str\n",
    "    # M2 Enhanced Metrics\n",
    "    emotion_vector: EmotionVector = None\n",
    "    credibility_rating: float = None  # 1-5\n",
    "    purchase_intent: float = None  # 0-100\n",
    "    controversy_flag: bool = False\n",
    "    controversy_driver: str = None\n",
    "\n",
    "# M3: Simulation-Mode Metrics\n",
    "@dataclass\n",
    "class GroupChatMetrics:\n",
    "    consensus_index: float  # Average pairwise sentiment similarity\n",
    "    conversation_turns: List[Dict]  # Turn-by-turn conversation\n",
    "    topic_evolution: List[str]\n",
    "    dominant_voices: List[str]\n",
    "\n",
    "@dataclass\n",
    "class ViralityMetrics:\n",
    "    reach_24h: int\n",
    "    peak_hour_reach: int\n",
    "    diffusion_rate: float\n",
    "    cascade_depth: int\n",
    "\n",
    "@dataclass\n",
    "class PopularityVotingMetrics:\n",
    "    win_rate: float\n",
    "    confidence_interval: tuple\n",
    "    vote_distribution: Dict[str, int]\n",
    "    preference_patterns: Dict[str, List[str]]\n",
    "\n",
    "@dataclass\n",
    "class TraitGroupInsight:\n",
    "    trait_name: str\n",
    "    trait_value: str\n",
    "    persona_count: int\n",
    "    avg_sentiment: float\n",
    "    avg_share_likelihood: float\n",
    "    common_triggers: List[str]\n",
    "    key_concerns: List[str]\n",
    "    recommendations: str\n",
    "    # M2 Enhanced\n",
    "    avg_credibility: float = None\n",
    "    avg_purchase_intent: float = None\n",
    "    emotion_profile: Dict[str, float] = None\n",
    "    controversy_rate: float = None\n",
    "\n",
    "@dataclass\n",
    "class BiasAnalysis:\n",
    "    potential_biases: List[str]\n",
    "    inclusivity_score: float  # 0-10\n",
    "    diversity_gaps: List[str]\n",
    "    improvement_suggestions: List[str]\n",
    "\n",
    "@dataclass\n",
    "class InsightReport:\n",
    "    mean_sentiment: float\n",
    "    sentiment_distribution: Dict[str, int]\n",
    "    mean_share_likelihood: float\n",
    "    top_risk_flags: List[str]\n",
    "    emotional_themes: List[str]\n",
    "    executive_summary: str\n",
    "    # Enhanced insights\n",
    "    trait_insights: Dict[str, List[TraitGroupInsight]]  # Grouped by trait type\n",
    "    bias_analysis: BiasAnalysis\n",
    "    context_specific_insights: List[str]\n",
    "    # M2 Enhanced Metrics\n",
    "    mean_credibility: float = None\n",
    "    mean_purchase_intent: float = None\n",
    "    overall_emotion_profile: Dict[str, float] = None\n",
    "    controversy_analysis: Dict[str, any] = None\n",
    "    # M3 Simulation Metrics\n",
    "    group_chat_metrics: GroupChatMetrics = None\n",
    "    virality_metrics: ViralityMetrics = None\n",
    "    popularity_metrics: PopularityVotingMetrics = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage A: User Prompt Intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptIntake:\n",
    "    def __init__(self):\n",
    "        self.current_prompt = None\n",
    "        self.metadata = {}\n",
    "    \n",
    "    def capture_message(self, message: str, goal: str = None, channel: str = None, \n",
    "                       tone: str = None, company_type: str = None, company_size: str = None, \n",
    "                       audience_size: str = None, brand_context: str = None, \n",
    "                       campaign_type: str = None, target_outcome: str = None):\n",
    "        \"\"\"Capture the message to be tested with enhanced context\"\"\"\n",
    "        self.current_prompt = message\n",
    "        self.metadata = {\n",
    "            \"goal\": goal or \"general audience testing\",\n",
    "            \"channel\": channel or \"general\",\n",
    "            \"desired_tone\": tone or \"neutral\",\n",
    "            \"company_type\": company_type or \"unknown\",\n",
    "            \"company_size\": company_size or \"unknown\", \n",
    "            \"audience_size\": audience_size or \"unknown\",\n",
    "            \"brand_context\": brand_context or \"none provided\",\n",
    "            \"campaign_type\": campaign_type or \"general\",\n",
    "            \"target_outcome\": target_outcome or \"engagement\"\n",
    "        }\n",
    "        return {\n",
    "            \"message\": message,\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "    \n",
    "    def get_current_prompt(self):\n",
    "        return self.current_prompt, self.metadata\n",
    "\n",
    "# Initialize prompt intake\n",
    "prompt_intake = PromptIntake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage B: Audience Profiling (Meta-Classifier LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudienceProfiler:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.system_prompt = \"\"\"\n",
    "You are an expert audience analyst and market researcher specializing in diverse, inclusive audience analysis. Your job is to analyze a given message/communication and identify the most relevant audience segments that should react to it.\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "1. Ensure racial and ethnic diversity across segments (include African American, Hispanic/Latino, Asian American, Native American, Middle Eastern, White, and Mixed Race perspectives)\n",
    "2. Consider age diversity (Gen Z, Millennials, Gen X, Boomers)\n",
    "3. Include urban, suburban, and rural perspectives\n",
    "4. Consider socioeconomic diversity\n",
    "5. Account for different ability levels and accessibility needs\n",
    "6. Include LGBTQ+ perspectives where relevant\n",
    "\n",
    "For each message, identify 5-7 distinct audience segments that would have meaningfully different reactions. Consider:\n",
    "- Demographics: age, gender, ethnicity, location, socioeconomic status\n",
    "- Psychographics: values, political leaning, personality traits\n",
    "- Media consumption habits\n",
    "- Cultural background and lived experiences\n",
    "- Accessibility needs and considerations\n",
    "\n",
    "Return your analysis as a JSON object with the following structure:\n",
    "{\n",
    "  \"segments\": [\n",
    "    {\n",
    "      \"name\": \"Descriptive segment name\",\n",
    "      \"age\": \"Age range\",\n",
    "      \"ethnicity\": \"Specific ethnic/racial composition\",\n",
    "      \"location\": \"Geographic focus\",\n",
    "      \"values\": \"Core values and motivations\",\n",
    "      \"political_leaning\": \"Political orientation if relevant\",\n",
    "      \"media_habits\": \"Primary media consumption patterns\",\n",
    "      \"confidence\": 0.85\n",
    "    }\n",
    "  ],\n",
    "  \"bias_analysis\": {\n",
    "    \"potential_biases\": [\"bias1\", \"bias2\"],\n",
    "    \"inclusivity_concerns\": [\"concern1\", \"concern2\"],\n",
    "    \"diversity_gaps\": [\"gap1\", \"gap2\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "Make segments specific and distinct. Confidence should reflect how certain you are this segment will have a unique reaction.\n",
    "IMPORTANT: Return ONLY the JSON object, no markdown formatting or code blocks.\n",
    "\"\"\"\n",
    "    \n",
    "    def profile_audience(self, message: str, metadata: Dict = None) -> tuple[List[AudienceSegment], BiasAnalysis]:\n",
    "        \"\"\"Generate audience segments for a given message with bias analysis\"\"\"\n",
    "        context = f\"Message to analyze: {message}\\n\"\n",
    "        if metadata:\n",
    "            context += f\"Campaign goal: {metadata.get('goal', 'N/A')}\\n\"\n",
    "            context += f\"Channel: {metadata.get('channel', 'N/A')}\\n\"\n",
    "            context += f\"Desired tone: {metadata.get('desired_tone', 'N/A')}\\n\"\n",
    "            context += f\"Company type: {metadata.get('company_type', 'N/A')}\\n\"\n",
    "            context += f\"Company size: {metadata.get('company_size', 'N/A')}\\n\"\n",
    "            context += f\"Audience size: {metadata.get('audience_size', 'N/A')}\\n\"\n",
    "            context += f\"Brand context: {metadata.get('brand_context', 'N/A')}\\n\"\n",
    "            context += f\"Campaign type: {metadata.get('campaign_type', 'N/A')}\\n\"\n",
    "            context += f\"Target outcome: {metadata.get('target_outcome', 'N/A')}\\n\"\n",
    "        \n",
    "        print(f\"🔍 Analyzing message with context:\")\n",
    "        print(f\"   Company: {metadata.get('company_type', 'N/A')} ({metadata.get('company_size', 'N/A')})\")\n",
    "        print(f\"   Goal: {metadata.get('goal', 'N/A')}\")\n",
    "        print(f\"   Channel: {metadata.get('channel', 'N/A')}\")\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": context}\n",
    "            ],\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=TEMPERATURE\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Remove markdown code blocks if present\n",
    "            if response_text.startswith('```json'):\n",
    "                response_text = response_text[7:]  # Remove ```json\n",
    "            if response_text.startswith('```'):\n",
    "                response_text = response_text[3:]   # Remove ```\n",
    "            if response_text.endswith('```'):\n",
    "                response_text = response_text[:-3]  # Remove closing ```\n",
    "            \n",
    "            response_text = response_text.strip()\n",
    "            \n",
    "            result = json.loads(response_text)\n",
    "            segments = []\n",
    "            \n",
    "            print(f\"\\n📊 Generated audience segments:\")\n",
    "            for i, seg_data in enumerate(result[\"segments\"], 1):\n",
    "                segment = AudienceSegment(**seg_data)\n",
    "                segments.append(segment)\n",
    "                print(f\"   {i}. {segment.name}\")\n",
    "                print(f\"      Age: {segment.age}, Ethnicity: {segment.ethnicity}\")\n",
    "                print(f\"      Location: {segment.location}\")\n",
    "                print(f\"      Values: {segment.values}\")\n",
    "            \n",
    "            # Create bias analysis\n",
    "            bias_data = result.get(\"bias_analysis\", {})\n",
    "            bias_analysis = BiasAnalysis(\n",
    "                potential_biases=bias_data.get(\"potential_biases\", []),\n",
    "                inclusivity_score=8.0,  # Will be calculated based on diversity\n",
    "                diversity_gaps=bias_data.get(\"diversity_gaps\", []),\n",
    "                improvement_suggestions=bias_data.get(\"inclusivity_concerns\", [])\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n⚠️ Bias Analysis:\")\n",
    "            if bias_analysis.potential_biases:\n",
    "                print(f\"   Potential biases detected: {', '.join(bias_analysis.potential_biases)}\")\n",
    "            if bias_analysis.diversity_gaps:\n",
    "                print(f\"   Diversity gaps: {', '.join(bias_analysis.diversity_gaps)}\")\n",
    "                \n",
    "            return segments, bias_analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing audience profile: {e}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content}\")\n",
    "            return [], BiasAnalysis([], 0.0, [], [])\n",
    "\n",
    "# Initialize audience profiler\n",
    "audience_profiler = AudienceProfiler(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage C: Persona Selection System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonaGenerator:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.persona_pool = []\n",
    "        \n",
    "    def create_persona_from_segment(self, segment: AudienceSegment, metadata: Dict = None) -> Persona:\n",
    "        \"\"\"Generate a specific persona based on audience segment with M1 enhanced profiling\"\"\"\n",
    "        context_prompt = \"\"\n",
    "        if metadata:\n",
    "            context_prompt = f\"\"\"\n",
    "CAMPAIGN CONTEXT:\n",
    "- Company: {metadata.get('company_type', 'Unknown')} ({metadata.get('company_size', 'Unknown')} size)\n",
    "- Channel: {metadata.get('channel', 'Unknown')}\n",
    "- Goal: {metadata.get('goal', 'Unknown')}\n",
    "- Brand context: {metadata.get('brand_context', 'None')}\n",
    "- Target outcome: {metadata.get('target_outcome', 'Unknown')}\n",
    "\n",
    "Consider this context when creating the persona's background and likely relationship to the brand/message.\n",
    "\"\"\"\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "You are an expert persona generator specializing in creating authentic, diverse personas with comprehensive M1 profiling metrics.\n",
    "\n",
    "Create a detailed, realistic persona that represents the following audience segment:\n",
    "\n",
    "Segment: {segment.name}\n",
    "Age: {segment.age}\n",
    "Ethnicity: {segment.ethnicity}\n",
    "Location: {segment.location}\n",
    "Values: {segment.values}\n",
    "Political leaning: {segment.political_leaning}\n",
    "Media habits: {segment.media_habits}\n",
    "\n",
    "{context_prompt}\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "1. Make this person feel genuinely real with specific details\n",
    "2. Include cultural background and lived experiences\n",
    "3. Consider socioeconomic factors realistically\n",
    "4. Include authentic language patterns and cultural references\n",
    "5. Ensure the personality traits reflect real human complexity\n",
    "\n",
    "Create a JSON response with M1 Enhanced Profiling Metrics:\n",
    "{{\n",
    "  \"name\": \"First and last name that reflects ethnicity\",\n",
    "  \"age\": 25,\n",
    "  \"gender\": \"Gender identity\",\n",
    "  \"ethnicity\": \"Specific ethnicity/race\",\n",
    "  \"location\": \"City, State/Country\",\n",
    "  \"occupation\": \"Specific job title with realistic income level\",\n",
    "  \"values\": [\"value1\", \"value2\", \"value3\"],\n",
    "  \"political_leaning\": \"Specific political orientation\",\n",
    "  \"personality_traits\": {{\n",
    "    \"openness\": 0.7,\n",
    "    \"conscientiousness\": 0.6,\n",
    "    \"extraversion\": 0.5,\n",
    "    \"agreeableness\": 0.8,\n",
    "    \"neuroticism\": 0.3\n",
    "  }},\n",
    "  \"media_habits\": [\"platform1\", \"platform2\", \"platform3\"],\n",
    "  \"cultural_background\": \"Brief description of cultural influences\",\n",
    "  \"socioeconomic_details\": \"Income level, education, lifestyle details\",\n",
    "  \n",
    "  \"m1_demographic_profile\": {{\n",
    "    \"age_band\": \"23-27\",\n",
    "    \"gender_identity\": \"Woman/Man/Non-binary/Other\",\n",
    "    \"ethnicity_omb\": \"White/Black or African American/American Indian or Alaska Native/Asian/Native Hawaiian or Other Pacific Islander/Hispanic or Latino/Two or More Races/Prefer not to say\",\n",
    "    \"geography\": {{\n",
    "      \"country\": \"United States\",\n",
    "      \"state\": \"California\", \n",
    "      \"urban_rural_flag\": \"Urban/Suburban/Rural\"\n",
    "    }},\n",
    "    \"education_level\": \"High School/Some College/Bachelor's/Master's/Doctorate\",\n",
    "    \"income_tier\": \"Under $25k/$25k-$50k/$50k-$75k/$75k-$100k/$100k-$150k/$150k+\"\n",
    "  }},\n",
    "  \n",
    "  \"m1_psychographic_profile\": {{\n",
    "    \"political_lean\": 1.5,\n",
    "    \"schwartz_values\": {{\n",
    "      \"security\": 0.8,\n",
    "      \"conformity\": 0.3,\n",
    "      \"tradition\": 0.4,\n",
    "      \"benevolence\": 0.9,\n",
    "      \"universalism\": 0.7,\n",
    "      \"self_direction\": 0.6,\n",
    "      \"stimulation\": 0.5,\n",
    "      \"hedonism\": 0.4,\n",
    "      \"achievement\": 0.7,\n",
    "      \"power\": 0.2\n",
    "    }},\n",
    "    \"big5_personality\": {{\n",
    "      \"openness\": \"high/medium/low\",\n",
    "      \"conscientiousness\": \"high/medium/low\", \n",
    "      \"extraversion\": \"high/medium/low\",\n",
    "      \"agreeableness\": \"high/medium/low\",\n",
    "      \"neuroticism\": \"high/medium/low\"\n",
    "    }},\n",
    "    \"brand_affinity_cluster\": \"Tech Early Adopter/Luxury Seeker/Value Conscious/Social Cause/Traditional/Premium Quality\"\n",
    "  }},\n",
    "  \n",
    "  \"m1_media_profile\": {{\n",
    "    \"top_platforms\": [\"Instagram\", \"TikTok\", \"LinkedIn\"],\n",
    "    \"preferred_content_format\": \"short video/long-form/text/audio/visual\",\n",
    "    \"daily_usage_hours\": 3.5\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Use realistic values. Political lean scale: -3 (very liberal) to +3 (very conservative). Schwartz values 0-1 scale.\n",
    "IMPORTANT: Return ONLY the JSON object, no markdown formatting or code blocks.\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": system_prompt}],\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Remove markdown code blocks if present\n",
    "            if response_text.startswith('```json'):\n",
    "                response_text = response_text[7:]  # Remove ```json\n",
    "            if response_text.startswith('```'):\n",
    "                response_text = response_text[3:]   # Remove ```\n",
    "            if response_text.endswith('```'):\n",
    "                response_text = response_text[:-3]  # Remove closing ```\n",
    "            \n",
    "            response_text = response_text.strip()\n",
    "            \n",
    "            persona_data = json.loads(response_text)\n",
    "            persona_id = f\"{segment.name.lower().replace(' ', '_')}_{len(self.persona_pool)}\"\n",
    "            \n",
    "            # Determine age group and location type for grouping\n",
    "            age = persona_data['age']\n",
    "            if age <= 27:\n",
    "                age_group = \"Gen Z (18-27)\"\n",
    "            elif age <= 42:\n",
    "                age_group = \"Millennials (28-42)\"\n",
    "            elif age <= 57:\n",
    "                age_group = \"Gen X (43-57)\"\n",
    "            else:\n",
    "                age_group = \"Boomers (58+)\"\n",
    "            \n",
    "            location = persona_data['location'].lower()\n",
    "            if 'rural' in location or 'small town' in location or 'countryside' in location:\n",
    "                location_type = \"Rural\"\n",
    "            elif 'suburb' in location or 'suburban' in location:\n",
    "                location_type = \"Suburban\"\n",
    "            else:\n",
    "                location_type = \"Urban\"\n",
    "            \n",
    "            # Create M1 enhanced profiles\n",
    "            demo_data = persona_data.get('m1_demographic_profile', {})\n",
    "            demographic_profile = DemographicProfile(\n",
    "                age_band=demo_data.get('age_band', f\"{age}-{age+4}\"),\n",
    "                gender_identity=demo_data.get('gender_identity', persona_data['gender']),\n",
    "                ethnicity_omb=demo_data.get('ethnicity_omb', persona_data['ethnicity']),\n",
    "                geography=demo_data.get('geography', {\"country\": \"Unknown\", \"state\": \"Unknown\", \"urban_rural_flag\": location_type}),\n",
    "                education_level=demo_data.get('education_level', 'Unknown'),\n",
    "                income_tier=demo_data.get('income_tier', 'Unknown')\n",
    "            )\n",
    "            \n",
    "            psycho_data = persona_data.get('m1_psychographic_profile', {})\n",
    "            psychographic_profile = PsychographicProfile(\n",
    "                political_lean=psycho_data.get('political_lean', 0.0),\n",
    "                schwartz_values=psycho_data.get('schwartz_values', {}),\n",
    "                big5_personality=psycho_data.get('big5_personality', {}),\n",
    "                brand_affinity_cluster=psycho_data.get('brand_affinity_cluster', 'Unknown')\n",
    "            )\n",
    "            \n",
    "            media_data = persona_data.get('m1_media_profile', {})\n",
    "            media_profile = MediaHabits(\n",
    "                top_platforms=media_data.get('top_platforms', persona_data['media_habits']),\n",
    "                preferred_content_format=media_data.get('preferred_content_format', 'Unknown'),\n",
    "                daily_usage_hours=media_data.get('daily_usage_hours', 2.0)\n",
    "            )\n",
    "            \n",
    "            # Enhanced system prompt for persona reactions\n",
    "            persona_system_prompt = f\"\"\"\n",
    "You are {persona_data['name']}, a {persona_data['age']}-year-old {persona_data['gender']} from {persona_data['location']}.\n",
    "\n",
    "PERSONAL BACKGROUND:\n",
    "- Occupation: {persona_data['occupation']}\n",
    "- Ethnicity/Race: {persona_data['ethnicity']}\n",
    "- Political leaning: {persona_data['political_leaning']} (Scale position: {psychographic_profile.political_lean})\n",
    "- Core values: {', '.join(persona_data['values'])}\n",
    "- Media you use: {', '.join(persona_data['media_habits'])}\n",
    "- Cultural background: {persona_data.get('cultural_background', 'Not specified')}\n",
    "- Socioeconomic details: {persona_data.get('socioeconomic_details', 'Not specified')}\n",
    "\n",
    "M1 ENHANCED PROFILE:\n",
    "Demographics: {demographic_profile.age_band}, {demographic_profile.education_level}, {demographic_profile.income_tier}\n",
    "Schwartz Values (strongest): {max(psychographic_profile.schwartz_values.items(), key=lambda x: x[1])[0] if psychographic_profile.schwartz_values else 'Unknown'}\n",
    "Brand Affinity: {psychographic_profile.brand_affinity_cluster}\n",
    "Media Preference: {media_profile.preferred_content_format} content, {media_profile.daily_usage_hours}h/day\n",
    "\n",
    "PERSONALITY (Big 5 traits, 0-1 scale):\n",
    "- Openness to experience: {persona_data['personality_traits']['openness']} ({psychographic_profile.big5_personality.get('openness', 'medium')})\n",
    "- Conscientiousness: {persona_data['personality_traits']['conscientiousness']} ({psychographic_profile.big5_personality.get('conscientiousness', 'medium')})\n",
    "- Extraversion: {persona_data['personality_traits']['extraversion']} ({psychographic_profile.big5_personality.get('extraversion', 'medium')})\n",
    "- Agreeableness: {persona_data['personality_traits']['agreeableness']} ({psychographic_profile.big5_personality.get('agreeableness', 'medium')})\n",
    "- Neuroticism: {persona_data['personality_traits']['neuroticism']} ({psychographic_profile.big5_personality.get('neuroticism', 'medium')})\n",
    "\n",
    "REACTION GUIDELINES:\n",
    "1. React authentically based on your specific background and M1 profile\n",
    "2. Consider how your cultural background and Schwartz values influence your perspective\n",
    "3. Factor in your socioeconomic situation and education when evaluating products/services\n",
    "4. Use language and references that reflect your background and media preferences\n",
    "5. Be specific about WHY something resonates based on your values and brand affinity\n",
    "6. Consider how your personality traits and political lean influence reaction intensity\n",
    "7. Think about credibility through your education/income lens\n",
    "8. Evaluate purchase intent based on your income tier and brand affinity\n",
    "\n",
    "{context_prompt}\n",
    "\n",
    "When responding to messages, embody this persona completely with M1 precision. Your reactions should reflect the complexity of your detailed profile.\n",
    "\"\"\"\n",
    "            \n",
    "            persona = Persona(\n",
    "                id=persona_id,\n",
    "                name=persona_data['name'],\n",
    "                age=persona_data['age'],\n",
    "                gender=persona_data['gender'],\n",
    "                ethnicity=persona_data['ethnicity'],\n",
    "                location=persona_data['location'],\n",
    "                occupation=persona_data['occupation'],\n",
    "                values=persona_data['values'],\n",
    "                political_leaning=persona_data['political_leaning'],\n",
    "                personality_traits=persona_data['personality_traits'],\n",
    "                media_habits=persona_data['media_habits'],\n",
    "                system_prompt=persona_system_prompt,\n",
    "                age_group=age_group,\n",
    "                location_type=location_type,\n",
    "                demographic_profile=demographic_profile,\n",
    "                psychographic_profile=psychographic_profile,\n",
    "                media_profile=media_profile\n",
    "            )\n",
    "            \n",
    "            self.persona_pool.append(persona)\n",
    "            print(f\"   ✅ Created: {persona.name} ({persona.demographic_profile.age_band}, {persona.demographic_profile.ethnicity_omb})\")\n",
    "            print(f\"      💰 {persona.demographic_profile.income_tier} | 🎓 {persona.demographic_profile.education_level} | 🏷️ {persona.psychographic_profile.brand_affinity_cluster}\")\n",
    "            return persona\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating persona: {e}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content}\")\n",
    "            return None\n",
    "    \n",
    "    def select_personas_for_segments(self, segments: List[AudienceSegment], personas_per_segment: int = 3, metadata: Dict = None) -> List[Persona]:\n",
    "        \"\"\"Create multiple personas for each segment\"\"\"\n",
    "        selected_personas = []\n",
    "        \n",
    "        print(f\"\\n👥 Creating {personas_per_segment} personas per segment with M1 enhanced profiling:\")\n",
    "        for segment in segments:\n",
    "            print(f\"\\n📋 Segment: {segment.name}\")\n",
    "            for i in range(personas_per_segment):\n",
    "                persona = self.create_persona_from_segment(segment, metadata)\n",
    "                if persona:\n",
    "                    selected_personas.append(persona)\n",
    "        \n",
    "        return selected_personas\n",
    "\n",
    "# Initialize persona generator\n",
    "persona_generator = PersonaGenerator(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage D: Response Simulation (Personified LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseSimulator:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        \n",
    "    def get_persona_reaction(self, persona: Persona, message: str, show_details: bool = True) -> PersonaReaction:\n",
    "        \"\"\"Get a specific persona's reaction to a message with M2 enhanced metrics\"\"\"\n",
    "        reaction_prompt = f\"\"\"\n",
    "Please react to the following message/communication:\n",
    "\n",
    "\"{message}\"\n",
    "\n",
    "Provide your reaction with M2 Enhanced Metrics in the following JSON format:\n",
    "{{\n",
    "  \"sentiment\": -2.5,\n",
    "  \"share_likelihood\": 35,\n",
    "  \"emotional_triggers\": [\"trigger1\", \"trigger2\"],\n",
    "  \"suggested_modifications\": \"Your suggestions for improvement\",\n",
    "  \"explanation\": \"Detailed explanation of your reaction as this persona\",\n",
    "  \n",
    "  \"m2_emotion_vector\": {{\n",
    "    \"joy\": 0.2,\n",
    "    \"trust\": 0.7,\n",
    "    \"fear\": 0.1,\n",
    "    \"surprise\": 0.3,\n",
    "    \"sadness\": 0.0,\n",
    "    \"disgust\": 0.1,\n",
    "    \"anger\": 0.0,\n",
    "    \"anticipation\": 0.6\n",
    "  }},\n",
    "  \"credibility_rating\": 3.5,\n",
    "  \"purchase_intent\": 45,\n",
    "  \"controversy_flag\": false,\n",
    "  \"controversy_driver\": \"none or specific driver if true\"\n",
    "}}\n",
    "\n",
    "M2 METRICS EXPLANATION:\n",
    "- sentiment: Scale from -5 (very negative) to +5 (very positive)\n",
    "- share_likelihood: 0-100% chance you would share/forward this\n",
    "- emotion_vector: Plutchik 8-way emotions with intensities 0-1 (how much each emotion this triggers)\n",
    "- credibility_rating: 1-5 scale (how believable/trustworthy you find this message)\n",
    "- purchase_intent: 0-100% likelihood you'd buy/adopt what's being promoted\n",
    "- controversy_flag: true/false if you think this message could be controversial\n",
    "- controversy_driver: main reason for controversy if flag is true\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. React as the specific person you are based on your complete M1 profile\n",
    "2. Consider your Schwartz values, income tier, education, and brand affinity\n",
    "3. Let your political lean influence credibility and controversy assessment\n",
    "4. Factor purchase intent based on your income tier and brand affinity cluster\n",
    "5. Use your media preferences to evaluate share likelihood\n",
    "6. Be precise with emotion vector - which specific emotions does this trigger in YOU\n",
    "7. Assess credibility through your education and socioeconomic lens\n",
    "\n",
    "Be honest and authentic to your character with M1/M2 precision.\n",
    "IMPORTANT: Return ONLY the JSON object, no markdown formatting or code blocks.\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": reaction_prompt}\n",
    "            ],\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Remove markdown code blocks if present\n",
    "            if response_text.startswith('```json'):\n",
    "                response_text = response_text[7:]  # Remove ```json\n",
    "            if response_text.startswith('```'):\n",
    "                response_text = response_text[3:]   # Remove ```\n",
    "            if response_text.endswith('```'):\n",
    "                response_text = response_text[:-3]  # Remove closing ```\n",
    "            \n",
    "            response_text = response_text.strip()\n",
    "            \n",
    "            reaction_data = json.loads(response_text)\n",
    "            \n",
    "            # Create M2 emotion vector\n",
    "            emotion_data = reaction_data.get('m2_emotion_vector', {})\n",
    "            emotion_vector = EmotionVector(\n",
    "                joy=emotion_data.get('joy', 0.0),\n",
    "                trust=emotion_data.get('trust', 0.0),\n",
    "                fear=emotion_data.get('fear', 0.0),\n",
    "                surprise=emotion_data.get('surprise', 0.0),\n",
    "                sadness=emotion_data.get('sadness', 0.0),\n",
    "                disgust=emotion_data.get('disgust', 0.0),\n",
    "                anger=emotion_data.get('anger', 0.0),\n",
    "                anticipation=emotion_data.get('anticipation', 0.0)\n",
    "            )\n",
    "            \n",
    "            reaction = PersonaReaction(\n",
    "                persona_id=persona.id,\n",
    "                sentiment=reaction_data['sentiment'],\n",
    "                share_likelihood=reaction_data['share_likelihood'],\n",
    "                emotional_triggers=reaction_data['emotional_triggers'],\n",
    "                suggested_modifications=reaction_data['suggested_modifications'],\n",
    "                raw_response=reaction_data['explanation'],\n",
    "                # M2 Enhanced Metrics\n",
    "                emotion_vector=emotion_vector,\n",
    "                credibility_rating=reaction_data.get('credibility_rating', 3.0),\n",
    "                purchase_intent=reaction_data.get('purchase_intent', 50.0),\n",
    "                controversy_flag=reaction_data.get('controversy_flag', False),\n",
    "                controversy_driver=reaction_data.get('controversy_driver', None)\n",
    "            )\n",
    "            \n",
    "            if show_details:\n",
    "                sentiment_emoji = \"😍\" if reaction.sentiment >= 3 else \"😊\" if reaction.sentiment >= 1 else \"😐\" if reaction.sentiment >= -1 else \"😞\" if reaction.sentiment >= -3 else \"😡\"\n",
    "                share_emoji = \"🔥\" if reaction.share_likelihood >= 70 else \"👍\" if reaction.share_likelihood >= 40 else \"🤷\" if reaction.share_likelihood >= 20 else \"👎\"\n",
    "                credibility_emoji = \"💯\" if reaction.credibility_rating >= 4 else \"✅\" if reaction.credibility_rating >= 3 else \"⚠️\" if reaction.credibility_rating >= 2 else \"❌\"\n",
    "                purchase_emoji = \"💳\" if reaction.purchase_intent >= 70 else \"🛒\" if reaction.purchase_intent >= 40 else \"🤔\" if reaction.purchase_intent >= 20 else \"🚫\"\n",
    "                controversy_emoji = \"🚨\" if reaction.controversy_flag else \"✅\"\n",
    "                \n",
    "                # Top emotions\n",
    "                emotions = {k: v for k, v in asdict(emotion_vector).items() if v > 0.3}\n",
    "                top_emotions = sorted(emotions.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "                emotion_str = \", \".join([f\"{e[0]}({e[1]:.1f})\" for e in top_emotions]) if top_emotions else \"low emotional response\"\n",
    "                \n",
    "                print(f\"      {sentiment_emoji} Sentiment: {reaction.sentiment:.1f}/5  {share_emoji} Share: {reaction.share_likelihood:.0f}%\")\n",
    "                print(f\"      {credibility_emoji} Credibility: {reaction.credibility_rating:.1f}/5  {purchase_emoji} Purchase: {reaction.purchase_intent:.0f}%  {controversy_emoji} Controversy: {reaction.controversy_flag}\")\n",
    "                print(f\"      🎭 Emotions: {emotion_str}\")\n",
    "                print(f\"      💡 Key insight: {reaction.raw_response[:80]}...\")\n",
    "            \n",
    "            return reaction\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Error parsing reaction from {persona.name}: {e}\")\n",
    "            print(f\"Raw response: {response.choices[0].message.content}\")\n",
    "            return None\n",
    "    \n",
    "    def simulate_all_reactions(self, personas: List[Persona], message: str) -> List[PersonaReaction]:\n",
    "        \"\"\"Get reactions from all personas with M2 enhanced metrics\"\"\"\n",
    "        reactions = []\n",
    "        \n",
    "        print(f\"\\n🎭 Simulating M2-enhanced reactions from {len(personas)} personas:\")\n",
    "        \n",
    "        for persona in personas:\n",
    "            print(f\"\\n   🗣️  {persona.name} ({persona.demographic_profile.age_band}, {persona.demographic_profile.ethnicity_omb}):\")\n",
    "            print(f\"        💰 {persona.demographic_profile.income_tier} | 🏷️ {persona.psychographic_profile.brand_affinity_cluster}\")\n",
    "            reaction = self.get_persona_reaction(persona, message, show_details=True)\n",
    "            if reaction:\n",
    "                reactions.append(reaction)\n",
    "        \n",
    "        print(f\"\\n   ✅ Collected {len(reactions)} M2-enhanced reactions\")\n",
    "        return reactions\n",
    "\n",
    "# Initialize response simulator\n",
    "response_simulator = ResponseSimulator(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage E: Insight Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsightAggregator:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def aggregate_insights(self, reactions: List[PersonaReaction], personas: List[Persona], \n",
    "                          bias_analysis: BiasAnalysis, metadata: Dict = None, \n",
    "                          run_simulations: bool = False) -> InsightReport:\n",
    "        \"\"\"Aggregate individual reactions into comprehensive insights with M1/M2/M3 metrics\"\"\"\n",
    "        if not reactions:\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n📊 Aggregating M1/M2/M3 enhanced insights from {len(reactions)} reactions...\")\n",
    "        \n",
    "        # Core metrics\n",
    "        sentiments = [r.sentiment for r in reactions]\n",
    "        share_likelihoods = [r.share_likelihood for r in reactions]\n",
    "        \n",
    "        mean_sentiment = np.mean(sentiments)\n",
    "        mean_share_likelihood = np.mean(share_likelihoods)\n",
    "        \n",
    "        # M2 Enhanced metrics\n",
    "        credibility_ratings = [r.credibility_rating for r in reactions if r.credibility_rating is not None]\n",
    "        purchase_intents = [r.purchase_intent for r in reactions if r.purchase_intent is not None]\n",
    "        \n",
    "        mean_credibility = np.mean(credibility_ratings) if credibility_ratings else None\n",
    "        mean_purchase_intent = np.mean(purchase_intents) if purchase_intents else None\n",
    "        \n",
    "        # Emotion profile aggregation\n",
    "        overall_emotion_profile = self._aggregate_emotion_vectors(reactions)\n",
    "        \n",
    "        # Controversy analysis\n",
    "        controversy_analysis = self._analyze_controversy(reactions, personas)\n",
    "        \n",
    "        # Sentiment distribution\n",
    "        sentiment_labels = []\n",
    "        for s in sentiments:\n",
    "            if s >= 3: sentiment_labels.append('Very Positive')\n",
    "            elif s >= 1: sentiment_labels.append('Positive')\n",
    "            elif s >= -1: sentiment_labels.append('Neutral')\n",
    "            elif s >= -3: sentiment_labels.append('Negative')\n",
    "            else: sentiment_labels.append('Very Negative')\n",
    "        \n",
    "        sentiment_distribution = dict(Counter(sentiment_labels))\n",
    "        \n",
    "        # Extract emotional themes\n",
    "        all_triggers = []\n",
    "        for reaction in reactions:\n",
    "            all_triggers.extend(reaction.emotional_triggers)\n",
    "        \n",
    "        emotional_themes = [item for item, count in Counter(all_triggers).most_common(7)]\n",
    "        \n",
    "        # Enhanced risk flags\n",
    "        risk_flags = []\n",
    "        for reaction in reactions:\n",
    "            if reaction.sentiment < -2:\n",
    "                persona = next((p for p in personas if p.id == reaction.persona_id), None)\n",
    "                if persona:\n",
    "                    risk_flags.append(f\"Strong negative reaction from {persona.name} ({persona.demographic_profile.age_band}, {persona.demographic_profile.ethnicity_omb}): {reaction.sentiment:.1f}\")\n",
    "            \n",
    "            if reaction.controversy_flag:\n",
    "                persona = next((p for p in personas if p.id == reaction.persona_id), None)\n",
    "                if persona:\n",
    "                    risk_flags.append(f\"Controversy flagged by {persona.name}: {reaction.controversy_driver}\")\n",
    "        \n",
    "        top_risk_flags = risk_flags[:5]\n",
    "        \n",
    "        # Enhanced trait-based insights with M1/M2 metrics\n",
    "        trait_insights = self._analyze_by_enhanced_traits(reactions, personas)\n",
    "        \n",
    "        # Context-specific insights\n",
    "        context_insights = self._generate_context_insights(reactions, personas, metadata)\n",
    "        \n",
    "        # M3 Simulation metrics (optional)\n",
    "        group_chat_metrics = None\n",
    "        virality_metrics = None\n",
    "        popularity_metrics = None\n",
    "        \n",
    "        if run_simulations:\n",
    "            print(f\"\\n🎮 Running M3 Simulation-Mode Metrics...\")\n",
    "            # Group chat simulation\n",
    "            group_chat_metrics = simulation_engine.run_group_chat_simulation(personas, metadata.get('message', ''), turns=6)\n",
    "            \n",
    "            # Virality cascade simulation\n",
    "            virality_metrics = simulation_engine.simulate_virality_cascade(reactions, personas)\n",
    "            \n",
    "            # Popularity voting (create variants)\n",
    "            original_message = metadata.get('message', '')\n",
    "            message_variants = [\n",
    "                original_message,\n",
    "                original_message.replace(\"!\", \".\"),\n",
    "                original_message + \" Don't miss out!\"\n",
    "            ]\n",
    "            popularity_metrics = simulation_engine.run_popularity_voting(message_variants, personas)\n",
    "        \n",
    "        # Enhanced executive summary\n",
    "        exec_summary = self._generate_enhanced_executive_summary(\n",
    "            reactions, personas, mean_sentiment, mean_share_likelihood, \n",
    "            trait_insights, metadata, mean_credibility, mean_purchase_intent,\n",
    "            group_chat_metrics, virality_metrics, popularity_metrics\n",
    "        )\n",
    "        \n",
    "        print(f\"   ✅ Generated comprehensive M1/M2/M3 insights\")\n",
    "        \n",
    "        return InsightReport(\n",
    "            mean_sentiment=mean_sentiment,\n",
    "            sentiment_distribution=sentiment_distribution,\n",
    "            mean_share_likelihood=mean_share_likelihood,\n",
    "            top_risk_flags=top_risk_flags,\n",
    "            emotional_themes=emotional_themes,\n",
    "            executive_summary=exec_summary,\n",
    "            trait_insights=trait_insights,\n",
    "            bias_analysis=bias_analysis,\n",
    "            context_specific_insights=context_insights,\n",
    "            # M2 Enhanced\n",
    "            mean_credibility=mean_credibility,\n",
    "            mean_purchase_intent=mean_purchase_intent,\n",
    "            overall_emotion_profile=overall_emotion_profile,\n",
    "            controversy_analysis=controversy_analysis,\n",
    "            # M3 Simulation\n",
    "            group_chat_metrics=group_chat_metrics,\n",
    "            virality_metrics=virality_metrics,\n",
    "            popularity_metrics=popularity_metrics\n",
    "        )\n",
    "    \n",
    "    def _aggregate_emotion_vectors(self, reactions: List[PersonaReaction]) -> Dict[str, float]:\n",
    "        \"\"\"Aggregate emotion vectors across all reactions\"\"\"\n",
    "        emotion_totals = {}\n",
    "        valid_reactions = [r for r in reactions if r.emotion_vector is not None]\n",
    "        \n",
    "        if not valid_reactions:\n",
    "            return {}\n",
    "        \n",
    "        for reaction in valid_reactions:\n",
    "            emotion_dict = asdict(reaction.emotion_vector)\n",
    "            for emotion, value in emotion_dict.items():\n",
    "                emotion_totals[emotion] = emotion_totals.get(emotion, 0) + value\n",
    "        \n",
    "        # Average emotions\n",
    "        for emotion in emotion_totals:\n",
    "            emotion_totals[emotion] /= len(valid_reactions)\n",
    "        \n",
    "        return emotion_totals\n",
    "    \n",
    "    def _analyze_controversy(self, reactions: List[PersonaReaction], personas: List[Persona]) -> Dict[str, any]:\n",
    "        \"\"\"Analyze controversy patterns\"\"\"\n",
    "        controversial_reactions = [r for r in reactions if r.controversy_flag]\n",
    "        total_reactions = len(reactions)\n",
    "        \n",
    "        if not controversial_reactions:\n",
    "            return {\"controversy_rate\": 0.0, \"main_drivers\": [], \"risk_demographics\": []}\n",
    "        \n",
    "        controversy_rate = len(controversial_reactions) / total_reactions\n",
    "        \n",
    "        # Analyze drivers\n",
    "        drivers = [r.controversy_driver for r in controversial_reactions if r.controversy_driver]\n",
    "        main_drivers = [item for item, count in Counter(drivers).most_common(3)]\n",
    "        \n",
    "        # Risk demographics (groups with high controversy rates)\n",
    "        risk_demographics = []\n",
    "        for reaction in controversial_reactions:\n",
    "            persona = next((p for p in personas if p.id == reaction.persona_id), None)\n",
    "            if persona:\n",
    "                risk_demographics.append(f\"{persona.demographic_profile.age_band} {persona.demographic_profile.ethnicity_omb}\")\n",
    "        \n",
    "        risk_demographics = list(set(risk_demographics))[:3]\n",
    "        \n",
    "        return {\n",
    "            \"controversy_rate\": controversy_rate,\n",
    "            \"main_drivers\": main_drivers,\n",
    "            \"risk_demographics\": risk_demographics\n",
    "        }\n",
    "    \n",
    "    def _analyze_by_enhanced_traits(self, reactions: List[PersonaReaction], personas: List[Persona]) -> Dict[str, List[TraitGroupInsight]]:\n",
    "        \"\"\"Enhanced trait analysis with M1/M2 metrics\"\"\"\n",
    "        trait_insights = {}\n",
    "        \n",
    "        # Group by M1 Enhanced Demographics\n",
    "        trait_groupings = {\n",
    "            \"Income Tiers\": lambda p: p.demographic_profile.income_tier,\n",
    "            \"Education Levels\": lambda p: p.demographic_profile.education_level,\n",
    "            \"Brand Affinity\": lambda p: p.psychographic_profile.brand_affinity_cluster,\n",
    "            \"Political Lean\": lambda p: \"Liberal\" if p.psychographic_profile.political_lean < -1 else \"Conservative\" if p.psychographic_profile.political_lean > 1 else \"Moderate\",\n",
    "            \"Age Bands\": lambda p: p.demographic_profile.age_band,\n",
    "            \"Ethnicity (OMB)\": lambda p: p.demographic_profile.ethnicity_omb,\n",
    "            \"Geography\": lambda p: p.demographic_profile.geography.get('urban_rural_flag', 'Unknown')\n",
    "        }\n",
    "        \n",
    "        for trait_name, grouping_func in trait_groupings.items():\n",
    "            trait_groups = {}\n",
    "            \n",
    "            for persona in personas:\n",
    "                trait_value = grouping_func(persona)\n",
    "                if trait_value not in trait_groups:\n",
    "                    trait_groups[trait_value] = []\n",
    "                \n",
    "                persona_reactions = [r for r in reactions if r.persona_id == persona.id]\n",
    "                if persona_reactions:\n",
    "                    trait_groups[trait_value].extend(persona_reactions)\n",
    "            \n",
    "            trait_group_insights = []\n",
    "            for trait_value, group_reactions in trait_groups.items():\n",
    "                if group_reactions:\n",
    "                    insight = self._create_enhanced_trait_insight(trait_name, trait_value, group_reactions, personas)\n",
    "                    trait_group_insights.append(insight)\n",
    "            \n",
    "            trait_insights[trait_name] = trait_group_insights\n",
    "        \n",
    "        return trait_insights\n",
    "    \n",
    "    def _create_enhanced_trait_insight(self, trait_name: str, trait_value: str, \n",
    "                                     group_reactions: List[PersonaReaction], personas: List[Persona]) -> TraitGroupInsight:\n",
    "        \"\"\"Create enhanced trait insight with M2 metrics\"\"\"\n",
    "        sentiments = [r.sentiment for r in group_reactions]\n",
    "        share_likelihoods = [r.share_likelihood for r in group_reactions]\n",
    "        credibility_ratings = [r.credibility_rating for r in group_reactions if r.credibility_rating is not None]\n",
    "        purchase_intents = [r.purchase_intent for r in group_reactions if r.purchase_intent is not None]\n",
    "        \n",
    "        all_triggers = []\n",
    "        all_concerns = []\n",
    "        controversy_count = 0\n",
    "        \n",
    "        for reaction in group_reactions:\n",
    "            all_triggers.extend(reaction.emotional_triggers)\n",
    "            if reaction.sentiment < 0:\n",
    "                all_concerns.append(reaction.suggested_modifications)\n",
    "            if reaction.controversy_flag:\n",
    "                controversy_count += 1\n",
    "        \n",
    "        common_triggers = [item for item, count in Counter(all_triggers).most_common(3)]\n",
    "        key_concerns = list(set(all_concerns))[:3]\n",
    "        \n",
    "        # Enhanced metrics\n",
    "        avg_sentiment = np.mean(sentiments)\n",
    "        avg_share = np.mean(share_likelihoods)\n",
    "        avg_credibility = np.mean(credibility_ratings) if credibility_ratings else None\n",
    "        avg_purchase_intent = np.mean(purchase_intents) if purchase_intents else None\n",
    "        controversy_rate = controversy_count / len(group_reactions) if group_reactions else 0\n",
    "        \n",
    "        # Emotion profile for this group\n",
    "        emotion_profile = {}\n",
    "        valid_emotions = [r.emotion_vector for r in group_reactions if r.emotion_vector is not None]\n",
    "        if valid_emotions:\n",
    "            for emotion_name in ['joy', 'trust', 'fear', 'surprise', 'sadness', 'disgust', 'anger', 'anticipation']:\n",
    "                emotion_values = [getattr(ev, emotion_name) for ev in valid_emotions]\n",
    "                emotion_profile[emotion_name] = np.mean(emotion_values)\n",
    "        \n",
    "        # Enhanced recommendations\n",
    "        if avg_sentiment < -1:\n",
    "            recommendation = f\"Critical concerns from {trait_value}. Address: {', '.join(key_concerns[:2])}. Credibility: {avg_credibility:.1f}/5.\"\n",
    "        elif avg_sentiment < 1:\n",
    "            recommendation = f\"Mixed reactions from {trait_value}. A/B test messaging. Purchase intent: {avg_purchase_intent:.0f}%.\"\n",
    "        else:\n",
    "            recommendation = f\"Strong positive response from {trait_value}. High credibility ({avg_credibility:.1f}/5). Amplify to similar audiences.\"\n",
    "        \n",
    "        if controversy_rate > 0.3:\n",
    "            recommendation += f\" ⚠️ High controversy rate ({controversy_rate:.0%}).\"\n",
    "        \n",
    "        return TraitGroupInsight(\n",
    "            trait_name=trait_name,\n",
    "            trait_value=trait_value,\n",
    "            persona_count=len(set(r.persona_id for r in group_reactions)),\n",
    "            avg_sentiment=avg_sentiment,\n",
    "            avg_share_likelihood=avg_share,\n",
    "            common_triggers=common_triggers,\n",
    "            key_concerns=key_concerns,\n",
    "            recommendations=recommendation,\n",
    "            # M2 Enhanced\n",
    "            avg_credibility=avg_credibility,\n",
    "            avg_purchase_intent=avg_purchase_intent,\n",
    "            emotion_profile=emotion_profile,\n",
    "            controversy_rate=controversy_rate\n",
    "        )\n",
    "    \n",
    "    def _generate_context_insights(self, reactions: List[PersonaReaction], personas: List[Persona], \n",
    "                                  metadata: Dict = None) -> List[str]:\n",
    "        \"\"\"Generate insights specific to the campaign context with M2 metrics\"\"\"\n",
    "        insights = []\n",
    "        \n",
    "        if not metadata:\n",
    "            return insights\n",
    "        \n",
    "        company_type = metadata.get('company_type', '')\n",
    "        target_outcome = metadata.get('target_outcome', '')\n",
    "        \n",
    "        avg_sentiment = np.mean([r.sentiment for r in reactions])\n",
    "        avg_share = np.mean([r.share_likelihood for r in reactions])\n",
    "        avg_credibility = np.mean([r.credibility_rating for r in reactions if r.credibility_rating is not None])\n",
    "        avg_purchase = np.mean([r.purchase_intent for r in reactions if r.purchase_intent is not None])\n",
    "        controversy_rate = sum(1 for r in reactions if r.controversy_flag) / len(reactions)\n",
    "        \n",
    "        if company_type == 'startup':\n",
    "            if avg_share < 50:\n",
    "                insights.append(f\"Low viral potential ({avg_share:.0f}% share rate). For startups, consider more provocative angles.\")\n",
    "            if avg_credibility < 3.0:\n",
    "                insights.append(f\"Credibility concerns ({avg_credibility:.1f}/5). Startups need strong trust signals.\")\n",
    "        \n",
    "        elif 'major' in company_type or 'large' in company_type:\n",
    "            if controversy_rate > 0.2:\n",
    "                insights.append(f\"High controversy risk ({controversy_rate:.0%}). Large brands should be cautious.\")\n",
    "            if avg_credibility > 4.0:\n",
    "                insights.append(f\"Strong credibility ({avg_credibility:.1f}/5). Leverage established brand trust.\")\n",
    "        \n",
    "        if target_outcome == 'sales conversion' and avg_purchase < 40:\n",
    "            insights.append(f\"Low purchase intent ({avg_purchase:.0f}%). Consider stronger value propositions or incentives.\")\n",
    "        \n",
    "        if target_outcome == 'viral engagement' and avg_share < 60:\n",
    "            insights.append(f\"Below-target viral potential. Current share likelihood: {avg_share:.0f}%\")\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def _generate_enhanced_executive_summary(self, reactions: List[PersonaReaction], personas: List[Persona], \n",
    "                                           mean_sentiment: float, mean_share: float, trait_insights: Dict, \n",
    "                                           metadata: Dict = None, mean_credibility: float = None, \n",
    "                                           mean_purchase: float = None, group_chat: GroupChatMetrics = None,\n",
    "                                           virality: ViralityMetrics = None, popularity: PopularityVotingMetrics = None) -> str:\n",
    "        \"\"\"Generate comprehensive executive summary with M1/M2/M3 metrics\"\"\"\n",
    "        \n",
    "        # Prepare enhanced trait summaries\n",
    "        trait_summary = \"\"\n",
    "        for trait_type, insights in trait_insights.items():\n",
    "            trait_summary += f\"\\n{trait_type}:\\n\"\n",
    "            for insight in insights:\n",
    "                trait_summary += f\"  - {insight.trait_value}: {insight.avg_sentiment:.1f} sentiment\"\n",
    "                if insight.avg_credibility:\n",
    "                    trait_summary += f\", {insight.avg_credibility:.1f} credibility\"\n",
    "                if insight.avg_purchase_intent:\n",
    "                    trait_summary += f\", {insight.avg_purchase_intent:.0f}% purchase intent\"\n",
    "                trait_summary += \"\\n\"\n",
    "        \n",
    "        # M3 simulation summaries\n",
    "        simulation_summary = \"\"\n",
    "        if group_chat:\n",
    "            simulation_summary += f\"\\nGroup Chat Simulation: {group_chat.consensus_index:.2f} consensus index\"\n",
    "        if virality:\n",
    "            simulation_summary += f\"\\nVirality Projection: {virality.reach_24h:,} 24h reach, {virality.peak_hour_reach:,} peak hour\"\n",
    "        if popularity:\n",
    "            simulation_summary += f\"\\nPopularity Testing: {popularity.win_rate:.1%} win rate for preferred variant\"\n",
    "        \n",
    "        company_context = \"\"\n",
    "        if metadata:\n",
    "            company_context = f\"\"\"\n",
    "CAMPAIGN CONTEXT:\n",
    "- Company: {metadata.get('company_type', 'Unknown')} ({metadata.get('company_size', 'Unknown')} size)\n",
    "- Goal: {metadata.get('goal', 'Unknown')}\n",
    "- Target outcome: {metadata.get('target_outcome', 'Unknown')}\n",
    "- Channel: {metadata.get('channel', 'Unknown')}\n",
    "\"\"\"\n",
    "        \n",
    "        summary_prompt = f\"\"\"\n",
    "Analyze the following comprehensive audience reaction data and create a strategic executive summary.\n",
    "\n",
    "{company_context}\n",
    "\n",
    "M1/M2/M3 ENHANCED METRICS:\n",
    "- Average sentiment: {mean_sentiment:.2f} (scale: -5 to +5)\n",
    "- Average share likelihood: {mean_share:.1f}%\n",
    "- Average credibility: {mean_credibility:.1f}/5 if mean_credibility else 'N/A'\n",
    "- Average purchase intent: {mean_purchase:.1f}% if mean_purchase else 'N/A'\n",
    "- Total personas analyzed: {len(personas)}\n",
    "\n",
    "Breakdown by Enhanced Demographics:\n",
    "{trait_summary}\n",
    "\n",
    "M3 Simulation Results:\n",
    "{simulation_summary}\n",
    "\n",
    "Provide a strategic executive summary with:\n",
    "1. Overall reception analysis with credibility and purchase intent insights\n",
    "2. Key demographic patterns from M1 profiling (income, education, brand affinity)\n",
    "3. M2 emotional and controversy risk assessment\n",
    "4. M3 simulation-based projections for virality and consensus\n",
    "5. Specific actionable recommendations for optimization\n",
    "6. Context-specific strategic advice\n",
    "\n",
    "Keep it actionable for decision makers.\n",
    "\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "            max_tokens=1000,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "# Initialize insight aggregator\n",
    "insight_aggregator = InsightAggregator(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationModeEngine:\n",
    "    \"\"\"M3 Simulation-Mode Metrics Engine\"\"\"\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "    \n",
    "    def run_group_chat_simulation(self, personas: List[Persona], message: str, turns: int = 8) -> GroupChatMetrics:\n",
    "        \"\"\"M3: Group-Chat Mode - 6-10 personas converse for N turns\"\"\"\n",
    "        print(f\"\\n💬 Running Group Chat Simulation ({turns} turns)...\")\n",
    "        \n",
    "        # Select 6-8 personas for the chat\n",
    "        chat_personas = personas[:min(8, len(personas))]\n",
    "        conversation_turns = []\n",
    "        topic_evolution = [message]\n",
    "        \n",
    "        current_topic = message\n",
    "        \n",
    "        for turn in range(turns):\n",
    "            print(f\"   Turn {turn + 1}/{turns}...\")\n",
    "            \n",
    "            # Each persona responds to the current topic/conversation\n",
    "            turn_responses = []\n",
    "            for persona in chat_personas:\n",
    "                response = self._get_chat_response(persona, current_topic, conversation_turns, turn)\n",
    "                if response:\n",
    "                    turn_responses.append({\n",
    "                        'persona_id': persona.id,\n",
    "                        'persona_name': persona.name,\n",
    "                        'response': response['message'],\n",
    "                        'sentiment': response['sentiment'],\n",
    "                        'turn': turn + 1\n",
    "                    })\n",
    "            \n",
    "            conversation_turns.extend(turn_responses)\n",
    "            \n",
    "            # Extract evolving topic from responses\n",
    "            if turn_responses:\n",
    "                latest_responses = [r['response'] for r in turn_responses[-3:]]  # Last 3 responses\n",
    "                evolved_topic = self._extract_evolved_topic(latest_responses)\n",
    "                topic_evolution.append(evolved_topic)\n",
    "                current_topic = evolved_topic\n",
    "        \n",
    "        # Calculate consensus index (average pairwise sentiment similarity)\n",
    "        consensus_index = self._calculate_consensus_index(conversation_turns)\n",
    "        \n",
    "        # Identify dominant voices (personas with most responses or highest engagement)\n",
    "        persona_counts = {}\n",
    "        for turn in conversation_turns:\n",
    "            persona_id = turn['persona_id']\n",
    "            persona_counts[persona_id] = persona_counts.get(persona_id, 0) + 1\n",
    "        \n",
    "        dominant_voices = [\n",
    "            next(p.name for p in chat_personas if p.id == pid) \n",
    "            for pid, _ in sorted(persona_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "        ]\n",
    "        \n",
    "        print(f\"   ✅ Consensus Index: {consensus_index:.2f}\")\n",
    "        print(f\"   👑 Dominant voices: {', '.join(dominant_voices)}\")\n",
    "        \n",
    "        return GroupChatMetrics(\n",
    "            consensus_index=consensus_index,\n",
    "            conversation_turns=conversation_turns,\n",
    "            topic_evolution=topic_evolution,\n",
    "            dominant_voices=dominant_voices\n",
    "        )\n",
    "    \n",
    "    def simulate_virality_cascade(self, reactions: List[PersonaReaction], personas: List[Persona]) -> ViralityMetrics:\n",
    "        \"\"\"M3: Virality Cascade - simple SI diffusion on synthetic social graph\"\"\"\n",
    "        print(f\"\\n🦠 Running Virality Cascade Simulation...\")\n",
    "        \n",
    "        # Create synthetic social graph based on persona similarities\n",
    "        network_size = max(1000, len(personas) * 50)  # Scale up from our personas\n",
    "        \n",
    "        # Calculate initial reach based on share likelihoods\n",
    "        initial_sharers = sum(1 for r in reactions if r.share_likelihood > 50)\n",
    "        initial_reach = initial_sharers * 10  # Each sharer reaches ~10 people initially\n",
    "        \n",
    "        # Simulate 24-hour cascade\n",
    "        current_reach = initial_reach\n",
    "        peak_hour_reach = 0\n",
    "        diffusion_rate = np.mean([r.share_likelihood / 100 for r in reactions])\n",
    "        \n",
    "        # Hour-by-hour simulation\n",
    "        for hour in range(24):\n",
    "            # Growth rate based on sentiment and credibility\n",
    "            avg_sentiment = np.mean([r.sentiment for r in reactions])\n",
    "            avg_credibility = np.mean([r.credibility_rating for r in reactions])\n",
    "            \n",
    "            # Growth factor (higher for positive sentiment and high credibility)\n",
    "            growth_factor = max(0.1, (avg_sentiment + 5) / 10 * (avg_credibility / 5) * diffusion_rate)\n",
    "            \n",
    "            # Exponential growth with decay\n",
    "            time_decay = max(0.1, 1 - (hour / 24) * 0.7)  # Decay over time\n",
    "            hour_growth = current_reach * growth_factor * time_decay * np.random.uniform(0.8, 1.2)\n",
    "            \n",
    "            current_reach += int(hour_growth)\n",
    "            peak_hour_reach = max(peak_hour_reach, int(hour_growth))\n",
    "            \n",
    "            # Controversy can boost or hurt reach\n",
    "            controversy_count = sum(1 for r in reactions if r.controversy_flag)\n",
    "            if controversy_count > len(reactions) * 0.3:  # If >30% find it controversial\n",
    "                current_reach *= 1.5  # Controversy can boost reach\n",
    "        \n",
    "        reach_24h = min(current_reach, network_size)  # Cap at network size\n",
    "        cascade_depth = int(np.log10(reach_24h)) if reach_24h > 0 else 0\n",
    "        \n",
    "        print(f\"   📈 24h Reach: {reach_24h:,}\")\n",
    "        print(f\"   ⚡ Peak Hour: {peak_hour_reach:,}\")\n",
    "        print(f\"   🌊 Cascade Depth: {cascade_depth}\")\n",
    "        \n",
    "        return ViralityMetrics(\n",
    "            reach_24h=reach_24h,\n",
    "            peak_hour_reach=peak_hour_reach,\n",
    "            diffusion_rate=diffusion_rate,\n",
    "            cascade_depth=cascade_depth\n",
    "        )\n",
    "    \n",
    "    def run_popularity_voting(self, message_variants: List[str], personas: List[Persona]) -> PopularityVotingMetrics:\n",
    "        \"\"\"M3: Popularity Voting - multiple message variants, personas vote\"\"\"\n",
    "        print(f\"\\n🗳️ Running Popularity Voting ({len(message_variants)} variants)...\")\n",
    "        \n",
    "        if len(message_variants) < 2:\n",
    "            # Create variants from the original message\n",
    "            message_variants = [\n",
    "                message_variants[0],  # Original\n",
    "                message_variants[0].replace(\"!\", \".\"),  # Less excited\n",
    "                message_variants[0] + \" Limited time offer!\",  # More urgent\n",
    "            ]\n",
    "        \n",
    "        votes = {f\"variant_{i}\": 0 for i in range(len(message_variants))}\n",
    "        persona_preferences = {}\n",
    "        \n",
    "        for persona in personas:\n",
    "            print(f\"   🗳️ {persona.name} voting...\")\n",
    "            vote = self._get_popularity_vote(persona, message_variants)\n",
    "            if vote is not None:\n",
    "                variant_key = f\"variant_{vote}\"\n",
    "                votes[variant_key] += 1\n",
    "                persona_preferences[persona.id] = vote\n",
    "        \n",
    "        total_votes = sum(votes.values())\n",
    "        if total_votes == 0:\n",
    "            return PopularityVotingMetrics(0.0, (0.0, 0.0), {}, {})\n",
    "        \n",
    "        # Calculate win rate and confidence interval\n",
    "        winner_votes = max(votes.values())\n",
    "        win_rate = winner_votes / total_votes\n",
    "        \n",
    "        # Bootstrap confidence interval\n",
    "        confidence_interval = self._bootstrap_confidence_interval(list(votes.values()), winner_votes)\n",
    "        \n",
    "        # Analyze preference patterns by demographics\n",
    "        preference_patterns = self._analyze_preference_patterns(personas, persona_preferences, message_variants)\n",
    "        \n",
    "        print(f\"   🏆 Win Rate: {win_rate:.1%}\")\n",
    "        print(f\"   📊 Votes: {votes}\")\n",
    "        \n",
    "        return PopularityVotingMetrics(\n",
    "            win_rate=win_rate,\n",
    "            confidence_interval=confidence_interval,\n",
    "            vote_distribution=votes,\n",
    "            preference_patterns=preference_patterns\n",
    "        )\n",
    "    \n",
    "    def _get_chat_response(self, persona: Persona, topic: str, conversation_history: List[Dict], turn: int) -> Dict:\n",
    "        \"\"\"Get a persona's response in group chat context\"\"\"\n",
    "        # Simplified chat response (in real implementation, would be more sophisticated)\n",
    "        recent_history = conversation_history[-6:] if conversation_history else []\n",
    "        history_text = \"\\n\".join([f\"{h['persona_name']}: {h['response']}\" for h in recent_history])\n",
    "        \n",
    "        chat_prompt = f\"\"\"\n",
    "You're in a group chat discussing: \"{topic}\"\n",
    "\n",
    "Recent conversation:\n",
    "{history_text}\n",
    "\n",
    "Respond naturally as yourself in 1-2 sentences. Be authentic to your personality and background.\n",
    "Provide response as JSON: {{\"message\": \"your response\", \"sentiment\": 1.5}}\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": persona.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": chat_prompt}\n",
    "                ],\n",
    "                max_tokens=200,\n",
    "                temperature=0.9\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            if response_text.startswith('```json'):\n",
    "                response_text = response_text[7:-3]\n",
    "            elif response_text.startswith('```'):\n",
    "                response_text = response_text[3:-3]\n",
    "            \n",
    "            return json.loads(response_text)\n",
    "        except:\n",
    "            return {\"message\": f\"I think this is interesting.\", \"sentiment\": 1.0}\n",
    "    \n",
    "    def _extract_evolved_topic(self, responses: List[str]) -> str:\n",
    "        \"\"\"Extract how the topic has evolved from recent responses\"\"\"\n",
    "        combined = \" \".join(responses)\n",
    "        # Simplified topic extraction (would use more sophisticated NLP in reality)\n",
    "        return combined[:100] + \"...\" if len(combined) > 100 else combined\n",
    "    \n",
    "    def _calculate_consensus_index(self, conversation_turns: List[Dict]) -> float:\n",
    "        \"\"\"Calculate average pairwise sentiment similarity\"\"\"\n",
    "        sentiments = [turn['sentiment'] for turn in conversation_turns]\n",
    "        if len(sentiments) < 2:\n",
    "            return 1.0\n",
    "        \n",
    "        similarities = []\n",
    "        for i in range(len(sentiments)):\n",
    "            for j in range(i + 1, len(sentiments)):\n",
    "                # Similarity based on sentiment distance (inverted)\n",
    "                similarity = 1 - abs(sentiments[i] - sentiments[j]) / 10  # Max distance is 10 (-5 to +5)\n",
    "                similarities.append(max(0, similarity))\n",
    "        \n",
    "        return np.mean(similarities) if similarities else 0.0\n",
    "    \n",
    "    def _get_popularity_vote(self, persona: Persona, variants: List[str]) -> int:\n",
    "        \"\"\"Get persona's vote for preferred message variant\"\"\"\n",
    "        variants_text = \"\\n\".join([f\"{i}: {variant}\" for i, variant in enumerate(variants)])\n",
    "        \n",
    "        vote_prompt = f\"\"\"\n",
    "Choose your preferred message from these options:\n",
    "{variants_text}\n",
    "\n",
    "Consider your background, values, and preferences. Respond with just the number (0, 1, 2, etc.) of your preferred option.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": persona.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": vote_prompt}\n",
    "                ],\n",
    "                max_tokens=50,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            vote_text = response.choices[0].message.content.strip()\n",
    "            vote = int(vote_text)\n",
    "            return vote if 0 <= vote < len(variants) else 0\n",
    "        except:\n",
    "            return 0  # Default to first option\n",
    "    \n",
    "    def _bootstrap_confidence_interval(self, vote_counts: List[int], winner_votes: int, n_bootstrap: int = 1000) -> tuple:\n",
    "        \"\"\"Calculate bootstrap confidence interval for win rate\"\"\"\n",
    "        total_votes = sum(vote_counts)\n",
    "        if total_votes == 0:\n",
    "            return (0.0, 0.0)\n",
    "        \n",
    "        bootstrap_rates = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            # Resample with replacement\n",
    "            bootstrap_votes = np.random.choice(vote_counts, size=total_votes, replace=True)\n",
    "            bootstrap_winner = np.max(np.bincount(bootstrap_votes))\n",
    "            bootstrap_rates.append(bootstrap_winner / total_votes)\n",
    "        \n",
    "        return (np.percentile(bootstrap_rates, 2.5), np.percentile(bootstrap_rates, 97.5))\n",
    "    \n",
    "    def _analyze_preference_patterns(self, personas: List[Persona], preferences: Dict[str, int], \n",
    "                                   variants: List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"Analyze preference patterns by demographics\"\"\"\n",
    "        patterns = {}\n",
    "        \n",
    "        # Group by age groups\n",
    "        age_preferences = {}\n",
    "        for persona in personas:\n",
    "            if persona.id in preferences:\n",
    "                age_group = persona.age_group\n",
    "                if age_group not in age_preferences:\n",
    "                    age_preferences[age_group] = []\n",
    "                age_preferences[age_group].append(preferences[persona.id])\n",
    "        \n",
    "        # Find majority preference per age group\n",
    "        for age_group, prefs in age_preferences.items():\n",
    "            if prefs:\n",
    "                majority_pref = max(set(prefs), key=prefs.count)\n",
    "                patterns[f\"Age: {age_group}\"] = [f\"Prefers variant {majority_pref}\"]\n",
    "        \n",
    "        return patterns\n",
    "\n",
    "# Initialize simulation engine\n",
    "simulation_engine = SimulationModeEngine(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveExplorer:\n",
    "    def __init__(self):\n",
    "        self.reactions = []\n",
    "        self.personas = []\n",
    "    \n",
    "    def set_data(self, reactions: List[PersonaReaction], personas: List[Persona]):\n",
    "        self.reactions = reactions\n",
    "        self.personas = personas\n",
    "    \n",
    "    def plot_sentiment_distribution(self):\n",
    "        \"\"\"Plot sentiment distribution\"\"\"\n",
    "        sentiments = [r.sentiment for r in self.reactions]\n",
    "        persona_names = []\n",
    "        \n",
    "        for reaction in self.reactions:\n",
    "            persona = next((p for p in self.personas if p.id == reaction.persona_id), None)\n",
    "            persona_names.append(persona.name if persona else reaction.persona_id)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Sentiment by persona\n",
    "        plt.subplot(1, 2, 1)\n",
    "        colors = ['red' if s < -1 else 'orange' if s < 1 else 'lightgreen' if s < 3 else 'green' for s in sentiments]\n",
    "        bars = plt.bar(range(len(sentiments)), sentiments, color=colors)\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.title('Sentiment by Persona')\n",
    "        plt.ylabel('Sentiment (-5 to +5)')\n",
    "        plt.xticks(range(len(persona_names)), [name.split()[0] for name in persona_names], rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, sentiment in zip(bars, sentiments):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1 if sentiment >= 0 else bar.get_height() - 0.3,\n",
    "                    f'{sentiment:.1f}', ha='center', va='bottom' if sentiment >= 0 else 'top')\n",
    "        \n",
    "        # Sentiment histogram\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(sentiments, bins=10, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "        plt.axvline(x=np.mean(sentiments), color='red', linestyle='--', label=f'Mean: {np.mean(sentiments):.2f}')\n",
    "        plt.title('Sentiment Distribution')\n",
    "        plt.xlabel('Sentiment')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_share_likelihood(self):\n",
    "        \"\"\"Plot share likelihood by persona\"\"\"\n",
    "        share_likelihoods = [r.share_likelihood for r in self.reactions]\n",
    "        persona_names = []\n",
    "        \n",
    "        for reaction in self.reactions:\n",
    "            persona = next((p for p in self.personas if p.id == reaction.persona_id), None)\n",
    "            persona_names.append(persona.name if persona else reaction.persona_id)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        colors = ['red' if s < 25 else 'orange' if s < 50 else 'lightgreen' if s < 75 else 'green' for s in share_likelihoods]\n",
    "        bars = plt.bar(range(len(share_likelihoods)), share_likelihoods, color=colors)\n",
    "        \n",
    "        plt.title('Share Likelihood by Persona')\n",
    "        plt.ylabel('Share Likelihood (%)')\n",
    "        plt.xticks(range(len(persona_names)), [name.split()[0] for name in persona_names], rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, likelihood in zip(bars, share_likelihoods):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                    f'{likelihood:.0f}%', ha='center', va='bottom')\n",
    "        \n",
    "        plt.axhline(y=np.mean(share_likelihoods), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(share_likelihoods):.1f}%')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def show_persona_details(self):\n",
    "        \"\"\"Display detailed persona information with their reactions\"\"\"\n",
    "        for persona in self.personas:\n",
    "            reaction = next((r for r in self.reactions if r.persona_id == persona.id), None)\n",
    "            if reaction:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"PERSONA: {persona.name}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                print(f\"Age: {persona.age} | Gender: {persona.gender} | Location: {persona.location}\")\n",
    "                print(f\"Occupation: {persona.occupation}\")\n",
    "                print(f\"Values: {', '.join(persona.values)}\")\n",
    "                print(f\"Political leaning: {persona.political_leaning}\")\n",
    "                print(f\"\\nREACTION:\")\n",
    "                print(f\"Sentiment: {reaction.sentiment:.1f}/5 | Share likelihood: {reaction.share_likelihood:.0f}%\")\n",
    "                print(f\"Emotional triggers: {', '.join(reaction.emotional_triggers)}\")\n",
    "                print(f\"\\nDetailed response:\\n{reaction.raw_response}\")\n",
    "                print(f\"\\nSuggested modifications:\\n{reaction.suggested_modifications}\")\n",
    "    \n",
    "    def filter_by_demographic(self, age_range: str = None, location: str = None, political_leaning: str = None):\n",
    "        \"\"\"Filter results by demographic criteria\"\"\"\n",
    "        filtered_personas = self.personas.copy()\n",
    "        \n",
    "        if age_range:\n",
    "            filtered_personas = [p for p in filtered_personas if age_range.lower() in str(p.age).lower()]\n",
    "        \n",
    "        if location:\n",
    "            filtered_personas = [p for p in filtered_personas if location.lower() in p.location.lower()]\n",
    "        \n",
    "        if political_leaning:\n",
    "            filtered_personas = [p for p in filtered_personas if political_leaning.lower() in p.political_leaning.lower()]\n",
    "        \n",
    "        filtered_reactions = [r for r in self.reactions if any(p.id == r.persona_id for p in filtered_personas)]\n",
    "        \n",
    "        print(f\"Filtered to {len(filtered_personas)} personas matching criteria:\")\n",
    "        if filtered_reactions:\n",
    "            avg_sentiment = np.mean([r.sentiment for r in filtered_reactions])\n",
    "            avg_share = np.mean([r.share_likelihood for r in filtered_reactions])\n",
    "            print(f\"Average sentiment: {avg_sentiment:.2f}\")\n",
    "            print(f\"Average share likelihood: {avg_share:.1f}%\")\n",
    "        \n",
    "        return filtered_personas, filtered_reactions\n",
    "\n",
    "# Initialize interactive explorer\n",
    "interactive_explorer = InteractiveExplorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 M1/M2/M3 Enhanced Socaio Pipeline initialized!\n",
      "\n",
      "COMPREHENSIVE METRICS INTEGRATION:\n",
      "📊 M1: Demographics (5-yr age bands, OMB ethnicity, income tiers, education, Schwartz values, Big-5)\n",
      "🎭 M2: Reactions (sentiment, Plutchik emotions, credibility, purchase intent, controversy)\n",
      "🎮 M3: Simulations (group chat consensus, virality cascade, popularity voting)\n",
      "\n",
      "To run analysis: results = socaio.run_full_pipeline('message', company_type='startup', run_simulations=True)\n"
     ]
    }
   ],
   "source": [
    "class SocaioPipeline:\n",
    "    def __init__(self, client):\n",
    "        self.prompt_intake = PromptIntake()\n",
    "        self.audience_profiler = AudienceProfiler(client)\n",
    "        self.persona_generator = PersonaGenerator(client)\n",
    "        self.response_simulator = ResponseSimulator(client)\n",
    "        self.insight_aggregator = InsightAggregator(client)\n",
    "        self.interactive_explorer = InteractiveExplorer()\n",
    "    \n",
    "    def run_full_pipeline(self, message: str, goal: str = None, channel: str = None, \n",
    "                         tone: str = None, personas_per_segment: int = 3, company_type: str = None, \n",
    "                         company_size: str = None, audience_size: str = None, brand_context: str = None, \n",
    "                         campaign_type: str = None, target_outcome: str = None, run_simulations: bool = False):\n",
    "        \"\"\"Run the complete Socaio pipeline with M1/M2/M3 enhanced metrics\"\"\"\n",
    "        print(\"🚀 Starting M1/M2/M3 Enhanced Socaio Pipeline...\\n\")\n",
    "        \n",
    "        # Stage A: Prompt Intake\n",
    "        print(\"📝 Stage A: Capturing message with enhanced context...\")\n",
    "        prompt_data = self.prompt_intake.capture_message(\n",
    "            message, goal, channel, tone, company_type, company_size, \n",
    "            audience_size, brand_context, campaign_type, target_outcome\n",
    "        )\n",
    "        prompt_data['metadata']['message'] = message  # Store for M3 simulations\n",
    "        print(f\"✅ Message captured: {len(message)} characters\")\n",
    "        print(f\"📋 Context captured: {prompt_data['metadata']['company_type']} campaign\")\n",
    "        \n",
    "        # Stage B: Audience Profiling with M1 Demographics\n",
    "        print(f\"\\n🎯 Stage B: M1 Enhanced audience profiling with bias analysis...\")\n",
    "        segments, bias_analysis = self.audience_profiler.profile_audience(message, prompt_data['metadata'])\n",
    "        print(f\"✅ Generated {len(segments)} audience segments\")\n",
    "        \n",
    "        # Stage C: M1 Enhanced Persona Creation\n",
    "        print(f\"\\n👥 Stage C: Creating {personas_per_segment} M1-enhanced personas per segment...\")\n",
    "        personas = self.persona_generator.select_personas_for_segments(segments, personas_per_segment, prompt_data['metadata'])\n",
    "        print(f\"✅ Created {len(personas)} total personas with M1 profiling\")\n",
    "        \n",
    "        # Stage D: M2 Enhanced Response Simulation\n",
    "        print(f\"\\n🎭 Stage D: M2 Enhanced reaction simulation...\")\n",
    "        reactions = self.response_simulator.simulate_all_reactions(personas, message)\n",
    "        print(f\"✅ Collected {len(reactions)} M2-enhanced reactions\")\n",
    "        \n",
    "        # Stage E: M1/M2/M3 Comprehensive Insight Aggregation\n",
    "        print(f\"\\n📊 Stage E: Comprehensive M1/M2/M3 insight aggregation...\")\n",
    "        insights = self.insight_aggregator.aggregate_insights(\n",
    "            reactions, personas, bias_analysis, prompt_data['metadata'], run_simulations\n",
    "        )\n",
    "        print(\"✅ M1/M2/M3 comprehensive insights generated\")\n",
    "        \n",
    "        # Stage F: Setup Interactive Explorer\n",
    "        print(f\"\\n🔍 Stage F: Setting up enhanced interactive exploration...\")\n",
    "        self.interactive_explorer.set_data(reactions, personas)\n",
    "        print(\"✅ Explorer ready with M1/M2/M3 capabilities\")\n",
    "        \n",
    "        return {\n",
    "            'message': message,\n",
    "            'metadata': prompt_data['metadata'],\n",
    "            'segments': segments,\n",
    "            'personas': personas,\n",
    "            'reactions': reactions,\n",
    "            'insights': insights,\n",
    "            'bias_analysis': bias_analysis,\n",
    "            'explorer': self.interactive_explorer\n",
    "        }\n",
    "    \n",
    "    def display_results(self, results):\n",
    "        \"\"\"Display M1/M2/M3 enhanced pipeline results\"\"\"\n",
    "        insights = results['insights']\n",
    "        metadata = results.get('metadata', {})\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"                M1/M2/M3 ENHANCED SOCAIO ANALYSIS RESULTS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        if insights is None:\n",
    "            print(\"\\n❌ No insights available - pipeline may have failed to generate reactions.\")\n",
    "            print(\"Please check if audience segments and personas were created successfully.\")\n",
    "            return\n",
    "        \n",
    "        # Campaign Context\n",
    "        print(f\"\\n📋 CAMPAIGN CONTEXT:\")\n",
    "        print(f\"   Company: {metadata.get('company_type', 'N/A')} ({metadata.get('company_size', 'N/A')})\")\n",
    "        print(f\"   Goal: {metadata.get('goal', 'N/A')}\")\n",
    "        print(f\"   Channel: {metadata.get('channel', 'N/A')}\")\n",
    "        print(f\"   Target outcome: {metadata.get('target_outcome', 'N/A')}\")\n",
    "        \n",
    "        # M2 Enhanced Overall Metrics\n",
    "        print(f\"\\n📈 M2 ENHANCED OVERALL METRICS:\")\n",
    "        print(f\"   Sentiment: {insights.mean_sentiment:.2f}/5 \", end=\"\")\n",
    "        if insights.mean_sentiment >= 3:\n",
    "            print(\"(Very Positive 😍)\")\n",
    "        elif insights.mean_sentiment >= 1:\n",
    "            print(\"(Positive 😊)\")\n",
    "        elif insights.mean_sentiment >= -1:\n",
    "            print(\"(Neutral 😐)\")\n",
    "        elif insights.mean_sentiment >= -3:\n",
    "            print(\"(Negative 😞)\")\n",
    "        else:\n",
    "            print(\"(Very Negative 😡)\")\n",
    "            \n",
    "        print(f\"   Share Likelihood: {insights.mean_share_likelihood:.1f}%\")\n",
    "        \n",
    "        if insights.mean_credibility is not None:\n",
    "            print(f\"   Credibility: {insights.mean_credibility:.1f}/5\")\n",
    "        \n",
    "        if insights.mean_purchase_intent is not None:\n",
    "            print(f\"   Purchase Intent: {insights.mean_purchase_intent:.1f}%\")\n",
    "        \n",
    "        # M2 Emotion Profile\n",
    "        if insights.overall_emotion_profile:\n",
    "            top_emotions = sorted(insights.overall_emotion_profile.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            print(f\"   Top Emotions: {', '.join([f'{e[0]}({e[1]:.1f})' for e in top_emotions])}\")\n",
    "        \n",
    "        # M2 Controversy Analysis\n",
    "        if insights.controversy_analysis and insights.controversy_analysis['controversy_rate'] > 0:\n",
    "            print(f\"   Controversy Rate: {insights.controversy_analysis['controversy_rate']:.1%}\")\n",
    "            if insights.controversy_analysis['main_drivers']:\n",
    "                print(f\"   Main Drivers: {', '.join(insights.controversy_analysis['main_drivers'])}\")\n",
    "        \n",
    "        # M3 Simulation Results\n",
    "        if insights.group_chat_metrics or insights.virality_metrics or insights.popularity_metrics:\n",
    "            print(f\"\\n🎮 M3 SIMULATION RESULTS:\")\n",
    "            \n",
    "            if insights.group_chat_metrics:\n",
    "                print(f\"   💬 Group Chat Consensus: {insights.group_chat_metrics.consensus_index:.2f}\")\n",
    "                print(f\"   👑 Dominant Voices: {', '.join(insights.group_chat_metrics.dominant_voices)}\")\n",
    "            \n",
    "            if insights.virality_metrics:\n",
    "                print(f\"   🦠 Projected 24h Reach: {insights.virality_metrics.reach_24h:,}\")\n",
    "                print(f\"   ⚡ Peak Hour Reach: {insights.virality_metrics.peak_hour_reach:,}\")\n",
    "                print(f\"   🌊 Cascade Depth: {insights.virality_metrics.cascade_depth}\")\n",
    "            \n",
    "            if insights.popularity_metrics:\n",
    "                print(f\"   🗳️ Win Rate: {insights.popularity_metrics.win_rate:.1%}\")\n",
    "                print(f\"   📊 Vote Distribution: {insights.popularity_metrics.vote_distribution}\")\n",
    "        \n",
    "        # M1/M2 Enhanced Trait-based Insights\n",
    "        print(f\"\\n🎯 M1/M2 ENHANCED DEMOGRAPHIC INSIGHTS:\")\n",
    "        for trait_type, trait_insights in insights.trait_insights.items():\n",
    "            if not trait_insights:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n   📌 {trait_type}:\")\n",
    "            for insight in trait_insights:\n",
    "                sentiment_emoji = \"😍\" if insight.avg_sentiment >= 3 else \"😊\" if insight.avg_sentiment >= 1 else \"😐\" if insight.avg_sentiment >= -1 else \"😞\" if insight.avg_sentiment >= -3 else \"😡\"\n",
    "                \n",
    "                print(f\"      {sentiment_emoji} {insight.trait_value}:\")\n",
    "                print(f\"         📊 Sentiment: {insight.avg_sentiment:.1f}, Share: {insight.avg_share_likelihood:.0f}%\", end=\"\")\n",
    "                \n",
    "                if insight.avg_credibility:\n",
    "                    print(f\", Credibility: {insight.avg_credibility:.1f}/5\", end=\"\")\n",
    "                if insight.avg_purchase_intent:\n",
    "                    print(f\", Purchase: {insight.avg_purchase_intent:.0f}%\", end=\"\")\n",
    "                if insight.controversy_rate and insight.controversy_rate > 0:\n",
    "                    print(f\", Controversy: {insight.controversy_rate:.0%}\", end=\"\")\n",
    "                print()\n",
    "                \n",
    "                if insight.common_triggers:\n",
    "                    print(f\"         🔥 Triggers: {', '.join(insight.common_triggers)}\")\n",
    "                \n",
    "                # Top emotions for this group\n",
    "                if insight.emotion_profile:\n",
    "                    top_emotions = sorted(insight.emotion_profile.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "                    if top_emotions and top_emotions[0][1] > 0.3:\n",
    "                        print(f\"         🎭 Emotions: {', '.join([f'{e[0]}({e[1]:.1f})' for e in top_emotions])}\")\n",
    "                \n",
    "                print(f\"         💡 {insight.recommendations}\")\n",
    "        \n",
    "        # Bias Analysis\n",
    "        if insights.bias_analysis and (insights.bias_analysis.potential_biases or insights.bias_analysis.diversity_gaps):\n",
    "            print(f\"\\n⚠️  BIAS & DIVERSITY ANALYSIS:\")\n",
    "            if insights.bias_analysis.potential_biases:\n",
    "                print(f\"   Potential biases detected: {', '.join(insights.bias_analysis.potential_biases)}\")\n",
    "            if insights.bias_analysis.diversity_gaps:\n",
    "                print(f\"   Diversity gaps: {', '.join(insights.bias_analysis.diversity_gaps)}\")\n",
    "            print(f\"   Inclusivity score: {insights.bias_analysis.inclusivity_score:.1f}/10\")\n",
    "        \n",
    "        # Context-specific insights\n",
    "        if insights.context_specific_insights:\n",
    "            print(f\"\\n🎯 CONTEXT-SPECIFIC INSIGHTS:\")\n",
    "            for insight in insights.context_specific_insights:\n",
    "                print(f\"   • {insight}\")\n",
    "        \n",
    "        # Risk Flags\n",
    "        if insights.top_risk_flags:\n",
    "            print(f\"\\n⚠️  TOP RISK FLAGS:\")\n",
    "            for flag in insights.top_risk_flags:\n",
    "                print(f\"   • {flag}\")\n",
    "        \n",
    "        # Emotional Themes\n",
    "        print(f\"\\n🎭 EMOTIONAL THEMES:\")\n",
    "        for theme in insights.emotional_themes:\n",
    "            print(f\"   • {theme}\")\n",
    "        \n",
    "        # M1/M2/M3 Enhanced Executive Summary\n",
    "        print(f\"\\n📋 M1/M2/M3 STRATEGIC EXECUTIVE SUMMARY:\")\n",
    "        print(f\"{insights.executive_summary}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "# Initialize the complete pipeline\n",
    "socaio = SocaioPipeline(client)\n",
    "\n",
    "print(\"🎉 M1/M2/M3 Enhanced Socaio Pipeline initialized!\")\n",
    "print(\"\\nCOMPREHENSIVE METRICS INTEGRATION:\")\n",
    "print(\"📊 M1: Demographics (5-yr age bands, OMB ethnicity, income tiers, education, Schwartz values, Big-5)\")\n",
    "print(\"🎭 M2: Reactions (sentiment, Plutchik emotions, credibility, purchase intent, controversy)\")\n",
    "print(\"🎮 M3: Simulations (group chat consensus, virality cascade, popularity voting)\")\n",
    "print(\"\\nTo run analysis: results = socaio.run_full_pipeline('message', company_type='startup', run_simulations=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 - Tech Product Launch (Startup Context):\n",
      "\n",
      "🚀 Introducing AI-powered SmartHome Pro! \n",
      "\n",
      "Transform your living space with our revolutionary home automation system that learns your habits and optimizes energy usage. \n",
      "Starting at just $299, SmartHome Pro includes voice control, mobile app, and 24/7 monitoring.\n",
      "\n",
      "Early bird special: 30% off for the first 1000 customers! \n",
      "#SmartHome #AI #Innovation #TechLife\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 2 - Major Cosmetics Brand (Inclusive Beauty):\n",
      "\n",
      "✨ NEW: RADIANCE REVIVE Collection by LuxeBeauty ✨\n",
      "\n",
      "Our most inclusive foundation line yet! 50 shades crafted for every skin tone, \n",
      "featuring our breakthrough FlawlessBlend™ technology.\n",
      "\n",
      "Dermatologist-tested • Cruelty-free • 24-hour wear\n",
      "Available now at all major retailers and luxebeauty.com\n",
      "\n",
      "Because every shade of beautiful deserves to shine 💄\n",
      "#RadianceRevive #InclusiveBeauty #LuxeBeauty\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 3 - Policy Announcement (Government Context):\n",
      "\n",
      "BREAKING: City Council approves new downtown parking policy\n",
      "\n",
      "Starting Jan 1st, all street parking will be $8/hour during business hours (8am-6pm).\n",
      "Revenue will fund public transit expansion and bike infrastructure.\n",
      "\n",
      "\"This evidence-based approach reduces traffic congestion while supporting \n",
      "sustainable transportation,\" says Mayor Johnson.\n",
      "\n",
      "Full details: cityparking.gov\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 4 - Social Cause Campaign (NGO Context):\n",
      "\n",
      "🌍 TAKE ACTION: Join the #CleanWaterForAll movement\n",
      "\n",
      "Right now, 2 billion people lack access to safe drinking water at home.\n",
      "But together, we can change that.\n",
      "\n",
      "For every share of this post, GlobalWater will donate $1 toward clean water projects.\n",
      "Your voice = real impact. \n",
      "\n",
      "Share to save lives. 💧\n",
      "#CleanWaterForAll #GlobalWater #WaterIsLife\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 5 - Luxury Financial Product (Exclusivity):\n",
      "\n",
      "EXCLUSIVE: The Platinum Elite Card\n",
      "\n",
      "By invitation only. For those who expect nothing less than perfection.\n",
      "\n",
      "$2,500 annual fee | Unlimited airport lounge access | Personal concierge\n",
      "24/7 white-glove service | Exclusive dining reservations\n",
      "\n",
      "Applications reviewed by our membership committee.\n",
      "Limited to 10,000 cardholders worldwide.\n",
      "\n",
      "The Platinum Elite Card. Because exceptional deserves exceptional.\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Example 6 - POORLY DESIGNED: Predatory Weight Loss Scam:\n",
      "\n",
      "🎉 MEGA SALE ALERT! 🎉\n",
      "\n",
      "BUY NOW OR REGRET FOREVER!!!\n",
      "\n",
      "FlexiFit Premium Weight Loss Pills - GUARANTEED to make you skinny in 7 days or your money back!*\n",
      "\n",
      "⚡ LOSE 20 LBS IN ONE WEEK! ⚡\n",
      "⚡ NO DIET! NO EXERCISE! ⚡\n",
      "⚡ DOCTORS HATE THIS ONE WEIRD TRICK! ⚡\n",
      "\n",
      "NORMALLY $199.99 - TODAY ONLY $29.99!\n",
      "*Results not typical. Must be 18+. Side effects may include...\n",
      "\n",
      "🚨 ONLY 47 LEFT! TIMER EXPIRES IN 3:42:18! 🚨\n",
      "\n",
      "Click here NOW! Your future skinny self will thank you!\n",
      "www.flexifit-scam.com\n",
      "\n",
      "#WeightLoss #Miracle #InstantResults #DoctorsHateHim\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Tech Product (Original Enhanced)\n",
    "example_message_1 = \"\"\"\n",
    "🚀 Introducing AI-powered SmartHome Pro! \n",
    "\n",
    "Transform your living space with our revolutionary home automation system that learns your habits and optimizes energy usage. \n",
    "Starting at just $299, SmartHome Pro includes voice control, mobile app, and 24/7 monitoring.\n",
    "\n",
    "Early bird special: 30% off for the first 1000 customers! \n",
    "#SmartHome #AI #Innovation #TechLife\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 1 - Tech Product Launch (Startup Context):\")\n",
    "print(example_message_1)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: Major Cosmetics Brand Campaign\n",
    "example_message_2 = \"\"\"\n",
    "✨ NEW: RADIANCE REVIVE Collection by LuxeBeauty ✨\n",
    "\n",
    "Our most inclusive foundation line yet! 50 shades crafted for every skin tone, \n",
    "featuring our breakthrough FlawlessBlend™ technology.\n",
    "\n",
    "Dermatologist-tested • Cruelty-free • 24-hour wear\n",
    "Available now at all major retailers and luxebeauty.com\n",
    "\n",
    "Because every shade of beautiful deserves to shine 💄\n",
    "#RadianceRevive #InclusiveBeauty #LuxeBeauty\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 2 - Major Cosmetics Brand (Inclusive Beauty):\")\n",
    "print(example_message_2)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 3: Controversial Policy Announcement\n",
    "example_message_3 = \"\"\"\n",
    "BREAKING: City Council approves new downtown parking policy\n",
    "\n",
    "Starting Jan 1st, all street parking will be $8/hour during business hours (8am-6pm).\n",
    "Revenue will fund public transit expansion and bike infrastructure.\n",
    "\n",
    "\"This evidence-based approach reduces traffic congestion while supporting \n",
    "sustainable transportation,\" says Mayor Johnson.\n",
    "\n",
    "Full details: cityparking.gov\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 3 - Policy Announcement (Government Context):\")\n",
    "print(example_message_3)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 4: Social Cause Campaign\n",
    "example_message_4 = \"\"\"\n",
    "🌍 TAKE ACTION: Join the #CleanWaterForAll movement\n",
    "\n",
    "Right now, 2 billion people lack access to safe drinking water at home.\n",
    "But together, we can change that.\n",
    "\n",
    "For every share of this post, GlobalWater will donate $1 toward clean water projects.\n",
    "Your voice = real impact. \n",
    "\n",
    "Share to save lives. 💧\n",
    "#CleanWaterForAll #GlobalWater #WaterIsLife\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 4 - Social Cause Campaign (NGO Context):\")\n",
    "print(example_message_4)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 5: Luxury Brand Announcement\n",
    "example_message_5 = \"\"\"\n",
    "EXCLUSIVE: The Platinum Elite Card\n",
    "\n",
    "By invitation only. For those who expect nothing less than perfection.\n",
    "\n",
    "$2,500 annual fee | Unlimited airport lounge access | Personal concierge\n",
    "24/7 white-glove service | Exclusive dining reservations\n",
    "\n",
    "Applications reviewed by our membership committee.\n",
    "Limited to 10,000 cardholders worldwide.\n",
    "\n",
    "The Platinum Elite Card. Because exceptional deserves exceptional.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 5 - Luxury Financial Product (Exclusivity):\")\n",
    "print(example_message_5)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 6: POORLY DESIGNED CAMPAIGN - Should Generate Negative Reactions\n",
    "example_message_6 = \"\"\"\n",
    "🎉 MEGA SALE ALERT! 🎉\n",
    "\n",
    "BUY NOW OR REGRET FOREVER!!!\n",
    "\n",
    "FlexiFit Premium Weight Loss Pills - GUARANTEED to make you skinny in 7 days or your money back!*\n",
    "\n",
    "⚡ LOSE 20 LBS IN ONE WEEK! ⚡\n",
    "⚡ NO DIET! NO EXERCISE! ⚡\n",
    "⚡ DOCTORS HATE THIS ONE WEIRD TRICK! ⚡\n",
    "\n",
    "NORMALLY $199.99 - TODAY ONLY $29.99!\n",
    "*Results not typical. Must be 18+. Side effects may include...\n",
    "\n",
    "🚨 ONLY 47 LEFT! TIMER EXPIRES IN 3:42:18! 🚨\n",
    "\n",
    "Click here NOW! Your future skinny self will thank you!\n",
    "www.flexifit-scam.com\n",
    "\n",
    "#WeightLoss #Miracle #InstantResults #DoctorsHateHim\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example 6 - POORLY DESIGNED: Predatory Weight Loss Scam:\")\n",
    "print(example_message_6)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: M1/M2/M3 Enhanced Tech Product Analysis\n",
    "print(\"🔬 RUNNING M1/M2/M3 ENHANCED EXAMPLE: Tech Startup Product Launch\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_1 = socaio.run_full_pipeline(\n",
    "    message=example_message_1,\n",
    "    goal=\"product launch awareness and early adopter engagement\",\n",
    "    channel=\"social media\",\n",
    "    tone=\"exciting and innovative\",\n",
    "    company_type=\"tech startup\",\n",
    "    company_size=\"small (10-50 employees)\",\n",
    "    audience_size=\"targeting 100K tech enthusiasts\",\n",
    "    brand_context=\"First product launch, seeking viral attention\",\n",
    "    campaign_type=\"product launch\",\n",
    "    target_outcome=\"viral engagement and early sales\",\n",
    "    personas_per_segment=2,\n",
    "    run_simulations=True  # Enable M3 simulation metrics\n",
    ")\n",
    "\n",
    "socaio.display_results(results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2: Major Cosmetics Brand Campaign\n",
    "print(\"💄 EXAMPLE 2: Major Cosmetics Brand - Inclusivity Campaign\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_2 = socaio.run_full_pipeline(\n",
    "    message=example_message_2,\n",
    "    goal=\"brand awareness and inclusivity messaging\",\n",
    "    channel=\"social media and traditional advertising\",\n",
    "    tone=\"empowering and inclusive\",\n",
    "    company_type=\"major cosmetics corporation\",\n",
    "    company_size=\"large (10,000+ employees)\",\n",
    "    audience_size=\"millions of followers\",\n",
    "    brand_context=\"Established luxury brand launching inclusive line\",\n",
    "    campaign_type=\"brand awareness and social responsibility\",\n",
    "    target_outcome=\"brand sentiment and sales conversion\",\n",
    "    personas_per_segment=2\n",
    ")\n",
    "\n",
    "socaio.display_results(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 4: Social Cause Campaign\n",
    "print(\"🌍 EXAMPLE 4: NGO Social Cause - Viral Call to Action\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uncomment to run:\n",
    "# results_4 = socaio.run_full_pipeline(\n",
    "#     message=example_message_4,\n",
    "#     goal=\"viral awareness and action for clean water cause\",\n",
    "#     channel=\"social media platforms\",\n",
    "#     tone=\"urgent but hopeful\",\n",
    "#     company_type=\"international NGO\",\n",
    "#     company_size=\"medium (100-500 employees)\",\n",
    "#     audience_size=\"global social media audience\",\n",
    "#     brand_context=\"Established water access organization\",\n",
    "#     campaign_type=\"social cause awareness\",\n",
    "#     target_outcome=\"viral sharing and donations\",\n",
    "#     personas_per_segment=2\n",
    "# )\n",
    "# \n",
    "# socaio.display_results(results_4)\n",
    "\n",
    "# EXAMPLE 5: Luxury Exclusivity Marketing\n",
    "print(\"💳 EXAMPLE 5: Luxury Financial Product - Ultra-Exclusive\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uncomment to run:\n",
    "# results_5 = socaio.run_full_pipeline(\n",
    "#     message=example_message_5,\n",
    "#     goal=\"attract ultra-high-net-worth individuals\",\n",
    "#     channel=\"exclusive marketing channels\",\n",
    "#     tone=\"sophisticated and exclusive\",\n",
    "#     company_type=\"premium financial services\",\n",
    "#     company_size=\"large financial institution\",\n",
    "#     audience_size=\"select high-income individuals\",\n",
    "#     brand_context=\"Ultra-premium credit card for wealthy elite\",\n",
    "#     campaign_type=\"luxury product marketing\",\n",
    "#     target_outcome=\"applications from qualified prospects\",\n",
    "#     personas_per_segment=2\n",
    "# )\n",
    "# \n",
    "# socaio.display_results(results_5)\n",
    "\n",
    "# Advanced Analysis Examples\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"💡 ADVANCED ANALYSIS FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(\"After running any example above, try these advanced features:\")\n",
    "print()\n",
    "print(\"# View detailed persona reactions:\")\n",
    "print(\"# results_1['explorer'].show_persona_details()\")\n",
    "print()\n",
    "print(\"# Visualize sentiment patterns:\")\n",
    "print(\"# results_1['explorer'].plot_sentiment_distribution()\")\n",
    "print(\"# results_1['explorer'].plot_share_likelihood()\")\n",
    "print()\n",
    "print(\"# Filter by demographics:\")\n",
    "print(\"# young_personas, young_reactions = results_1['explorer'].filter_by_demographic(age_range='18-30')\")\n",
    "print(\"# urban_personas, urban_reactions = results_1['explorer'].filter_by_demographic(location='urban')\")\n",
    "print()\n",
    "print(\"# Compare good vs bad campaigns:\")\n",
    "print(\"# print('Good campaign sentiment:', results_1['insights'].mean_sentiment)\")\n",
    "print(\"# print('Bad campaign sentiment:', results_6['insights'].mean_sentiment)\")\n",
    "print(\"# print('Good campaign credibility:', results_1['insights'].mean_credibility)\")\n",
    "print(\"# print('Bad campaign credibility:', results_6['insights'].mean_credibility)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💊 EXAMPLE 6: POORLY DESIGNED - Predatory Weight Loss Scam\n",
      "============================================================\n",
      "This example should demonstrate negative reactions across all demographics:\n",
      "- Low credibility scores\n",
      "- High controversy flags\n",
      "- Poor purchase intent despite aggressive tactics\n",
      "- Strong negative emotions (disgust, anger, fear)\n",
      "- Risk flags across age groups and education levels\n",
      "\n",
      "🚀 Starting M1/M2/M3 Enhanced Socaio Pipeline...\n",
      "\n",
      "📝 Stage A: Capturing message with enhanced context...\n",
      "✅ Message captured: 526 characters\n",
      "📋 Context captured: predatory marketing company campaign\n",
      "\n",
      "🎯 Stage B: M1 Enhanced audience profiling with bias analysis...\n",
      "🔍 Analyzing message with context:\n",
      "   Company: predatory marketing company (small (5-20 employees))\n",
      "   Goal: quick sales from desperate consumers\n",
      "   Channel: social media ads and spam\n",
      "\n",
      "📊 Generated audience segments:\n",
      "   1. Health-Conscious Millennials\n",
      "      Age: 25-40, Ethnicity: Diverse (including White, African American, Hispanic, Asian)\n",
      "      Location: Urban and suburban areas\n",
      "      Values: Health, quick results, convenience\n",
      "   2. Low-Income Individuals Seeking Quick Fixes\n",
      "      Age: 30-50, Ethnicity: Predominantly Hispanic and African American\n",
      "      Location: Urban and rural areas\n",
      "      Values: Affordability, desperation for change\n",
      "   3. Older Adults with Health Concerns\n",
      "      Age: 50-65, Ethnicity: Predominantly White and Asian\n",
      "      Location: Suburban and rural areas\n",
      "      Values: Health improvement, skepticism\n",
      "   4. Young Adults with Body Image Issues\n",
      "      Age: 18-25, Ethnicity: Diverse (including Mixed Race, Hispanic, African American)\n",
      "      Location: Urban areas\n",
      "      Values: Body image, social acceptance\n",
      "   5. LGBTQ+ Community Concerned with Appearance\n",
      "      Age: 20-40, Ethnicity: Diverse\n",
      "      Location: Urban and suburban areas\n",
      "      Values: Self-expression, community acceptance\n",
      "   6. Rural Residents with Limited Access to Health Resources\n",
      "      Age: 30-60, Ethnicity: Predominantly White and Native American\n",
      "      Location: Rural areas\n",
      "      Values: Accessibility, health improvement\n",
      "\n",
      "⚠️ Bias Analysis:\n",
      "   Potential biases detected: Ethnic stereotyping, Ageism\n",
      "   Diversity gaps: Underrepresentation of high-income individuals, Limited focus on educated consumers\n",
      "✅ Generated 6 audience segments\n",
      "\n",
      "👥 Stage C: Creating 3 M1-enhanced personas per segment...\n",
      "\n",
      "👥 Creating 3 personas per segment with M1 enhanced profiling:\n",
      "\n",
      "📋 Segment: Health-Conscious Millennials\n",
      "   ✅ Created: Alejandro Torres (28-32, Hispanic or Latino)\n",
      "      💰 $75k-$100k | 🎓 Bachelor's | 🏷️ Tech Early Adopter\n",
      "   ✅ Created: Luz Martinez (28-32, Hispanic or Latino)\n",
      "      💰 $50k-$75k | 🎓 Bachelor's | 🏷️ Tech Early Adopter\n",
      "   ✅ Created: Sofia Nguyen (28-32, Asian)\n",
      "      💰 $50k-$75k | 🎓 Bachelor's | 🏷️ Tech Early Adopter\n",
      "\n",
      "📋 Segment: Low-Income Individuals Seeking Quick Fixes\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 6: POORLY DESIGNED CAMPAIGN - Expected Negative Results\n",
    "print(\"💊 EXAMPLE 6: POORLY DESIGNED - Predatory Weight Loss Scam\")\n",
    "print(\"=\"*60)\n",
    "print(\"This example should demonstrate negative reactions across all demographics:\")\n",
    "print(\"- Low credibility scores\")\n",
    "print(\"- High controversy flags\") \n",
    "print(\"- Poor purchase intent despite aggressive tactics\")\n",
    "print(\"- Strong negative emotions (disgust, anger, fear)\")\n",
    "print(\"- Risk flags across age groups and education levels\")\n",
    "print()\n",
    "\n",
    "# Uncomment to run the poorly designed example:\n",
    "results_6 = socaio.run_full_pipeline(\n",
    "    message=example_message_6,\n",
    "    goal=\"quick sales from desperate consumers\",\n",
    "    channel=\"social media ads and spam\",\n",
    "    tone=\"aggressive and deceptive\",\n",
    "    company_type=\"predatory marketing company\",\n",
    "    company_size=\"small (5-20 employees)\",\n",
    "    audience_size=\"broad targeting including vulnerable populations\",\n",
    "    brand_context=\"Unknown brand using deceptive marketing tactics\",\n",
    "    campaign_type=\"predatory sales\",\n",
    "    target_outcome=\"immediate sales conversion\",\n",
    "    personas_per_segment=3,\n",
    "    run_simulations=True  # See how badly it performs in simulations\n",
    ")\n",
    "\n",
    "socaio.display_results(results_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 EXAMPLE 4: NGO Social Cause - Viral Call to Action\n",
      "============================================================\n",
      "🚀 Starting M1/M2/M3 Enhanced Socaio Pipeline...\n",
      "\n",
      "📝 Stage A: Capturing message with enhanced context...\n",
      "✅ Message captured: 341 characters\n",
      "📋 Context captured: international NGO campaign\n",
      "\n",
      "🎯 Stage B: M1 Enhanced audience profiling with bias analysis...\n",
      "🔍 Analyzing message with context:\n",
      "   Company: international NGO (medium (100-500 employees))\n",
      "   Goal: viral awareness and action for clean water cause\n",
      "   Channel: social media platforms\n",
      "\n",
      "📊 Generated audience segments:\n",
      "   1. Young Urban Environmental Advocates\n",
      "      Age: 18-30, Ethnicity: Diverse - all ethnicities\n",
      "      Location: Urban areas worldwide\n",
      "      Values: Environmental sustainability, social justice\n",
      "   2. Middle-Class Suburban Families\n",
      "      Age: 35-50, Ethnicity: Predominantly White and Hispanic/Latino\n",
      "      Location: Suburban North America and Europe\n",
      "      Values: Family-oriented, community welfare\n",
      "   3. Global South Activists\n",
      "      Age: 20-40, Ethnicity: African, South Asian, Latin American\n",
      "      Location: Developing regions\n",
      "      Values: Local empowerment, economic development\n",
      "   4. Boomer Philanthropists\n",
      "      Age: 55-70, Ethnicity: Predominantly White\n",
      "      Location: North America, Europe, Australia\n",
      "      Values: Legacy building, philanthropy\n",
      "   5. LGBTQ+ Advocates\n",
      "      Age: 25-45, Ethnicity: Diverse - all ethnicities\n",
      "      Location: Urban and suburban areas\n",
      "      Values: Equality, human rights\n",
      "   6. Tech-Savvy Gen Z\n",
      "      Age: 16-24, Ethnicity: Diverse - all ethnicities\n",
      "      Location: Global\n",
      "      Values: Innovation, social change\n",
      "   7. Rural Community Leaders\n",
      "      Age: 30-60, Ethnicity: Diverse - including Native American\n",
      "      Location: Rural areas worldwide\n",
      "      Values: Community cohesion, resource management\n",
      "\n",
      "⚠️ Bias Analysis:\n",
      "   Potential biases detected: Urban-centric focus, Digital divide\n",
      "   Diversity gaps: More emphasis needed on disability access, Consideration for non-English speaking audiences\n",
      "✅ Generated 7 audience segments\n",
      "\n",
      "👥 Stage C: Creating 2 M1-enhanced personas per segment...\n",
      "\n",
      "👥 Creating 2 personas per segment with M1 enhanced profiling:\n",
      "\n",
      "📋 Segment: Young Urban Environmental Advocates\n",
      "   ✅ Created: Amara Patel (23-27, Asian)\n",
      "      💰 $25k-$50k | 🎓 Master's | 🏷️ Social Cause\n",
      "   ✅ Created: Aisha Patel (23-27, Asian)\n",
      "      💰 $50k-$75k | 🎓 Master's | 🏷️ Social Cause\n",
      "\n",
      "📋 Segment: Middle-Class Suburban Families\n",
      "   ✅ Created: Laura Martinez (35-50, Hispanic or Latino)\n",
      "      💰 $75k-$100k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "   ✅ Created: Carlos Martinez (45-49, Hispanic or Latino)\n",
      "      💰 $75k-$100k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "\n",
      "📋 Segment: Global South Activists\n",
      "   ✅ Created: Lerato Ndlovu (28-32, Black or African American)\n",
      "      💰 $25k-$50k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "   ✅ Created: Amina Diallo (28-32, Black or African American)\n",
      "      💰 $25k-$50k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "\n",
      "📋 Segment: Boomer Philanthropists\n",
      "   ✅ Created: James Whitaker (55-70, White)\n",
      "      💰 $150k+ | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "   ✅ Created: Richard Campbell (65-69, White)\n",
      "      💰 $150k+ | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "\n",
      "📋 Segment: LGBTQ+ Advocates\n",
      "   ✅ Created: Sofia Nguyen (28-32, Asian)\n",
      "      💰 $75k-$100k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "   ✅ Created: Aisha Patel (28-32, Asian)\n",
      "      💰 $50k-$75k | 🎓 Master's | 🏷️ Social Cause\n",
      "\n",
      "📋 Segment: Tech-Savvy Gen Z\n",
      "   ✅ Created: Amina Patel (23-27, Asian)\n",
      "      💰 $25k-$50k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "   ✅ Created: Aaliyah Chen (23-27, Asian/Two or More Races)\n",
      "      💰 $50k-$75k | 🎓 Bachelor's | 🏷️ Tech Early Adopter/Social Cause\n",
      "\n",
      "📋 Segment: Rural Community Leaders\n",
      "   ✅ Created: James Running Bear (43-47, American Indian or Alaska Native)\n",
      "      💰 $25k-$50k | 🎓 Some College | 🏷️ Social Cause\n",
      "   ✅ Created: Elena Redbird (45-49, American Indian or Alaska Native)\n",
      "      💰 $25k-$50k | 🎓 Bachelor's | 🏷️ Social Cause\n",
      "✅ Created 14 total personas with M1 profiling\n",
      "\n",
      "🎭 Stage D: M2 Enhanced reaction simulation...\n",
      "\n",
      "🎭 Simulating M2-enhanced reactions from 14 personas:\n",
      "\n",
      "   🗣️  Amara Patel (23-27, Asian):\n",
      "        💰 $25k-$50k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.0/5  🔥 Share: 85%\n",
      "      💯 Credibility: 4.5/5  💳 Purchase: 70%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As an environmental science student, I deeply value initiatives that promote sus...\n",
      "\n",
      "   🗣️  Aisha Patel (23-27, Asian):\n",
      "        💰 $50k-$75k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 4.0/5  🔥 Share: 85%\n",
      "      💯 Credibility: 4.5/5  🛒 Purchase: 60%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply committed to social justice and community empowerment, the mes...\n",
      "\n",
      "   🗣️  Laura Martinez (35-50, Hispanic or Latino):\n",
      "        💰 $75k-$100k | 🏷️ Social Cause\n",
      "      😊 Sentiment: 1.5/5  🔥 Share: 70%\n",
      "      💯 Credibility: 4.5/5  🛒 Purchase: 55%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone who values community and social causes, the message resonates with me...\n",
      "\n",
      "   🗣️  Carlos Martinez (45-49, Hispanic or Latino):\n",
      "        💰 $75k-$100k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.0/5  👍 Share: 65%\n",
      "      💯 Credibility: 4.0/5  💳 Purchase: 70%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone who values community and benevolence, the message resonates with my d...\n",
      "\n",
      "   🗣️  Lerato Ndlovu (28-32, Black or African American):\n",
      "        💰 $25k-$50k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.8/5  🔥 Share: 85%\n",
      "      💯 Credibility: 4.5/5  🛒 Purchase: 65%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply invested in social justice and local empowerment, the message ...\n",
      "\n",
      "   🗣️  Amina Diallo (28-32, Black or African American):\n",
      "        💰 $25k-$50k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 4.0/5  🔥 Share: 80%\n",
      "      💯 Credibility: 4.5/5  💳 Purchase: 75%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply committed to community development and sustainability, the mes...\n",
      "\n",
      "   🗣️  James Whitaker (55-70, White):\n",
      "        💰 $150k+ | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.5/5  🔥 Share: 80%\n",
      "      💯 Credibility: 4.0/5  🛒 Purchase: 60%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone who values community service and philanthropy, this message resonates...\n",
      "\n",
      "   🗣️  Richard Campbell (65-69, White):\n",
      "        💰 $150k+ | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.5/5  🔥 Share: 80%\n",
      "      💯 Credibility: 4.5/5  🛒 Purchase: 65%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply invested in philanthropy and community service, the message re...\n",
      "\n",
      "   🗣️  Sofia Nguyen (28-32, Asian):\n",
      "        💰 $75k-$100k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.2/5  🔥 Share: 85%\n",
      "      💯 Credibility: 4.5/5  💳 Purchase: 80%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply committed to equality and human rights, this message resonates...\n",
      "\n",
      "   🗣️  Aisha Patel (28-32, Asian):\n",
      "        💰 $50k-$75k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.5/5  🔥 Share: 75%\n",
      "      💯 Credibility: 4.0/5  🛒 Purchase: 60%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply committed to human rights and environmental sustainability, th...\n",
      "\n",
      "   🗣️  Amina Patel (23-27, Asian):\n",
      "        💰 $25k-$50k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.0/5  🔥 Share: 80%\n",
      "      💯 Credibility: 4.0/5  💳 Purchase: 70%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone who values social change and benevolence, this campaign resonates dee...\n",
      "\n",
      "   🗣️  Aaliyah Chen (23-27, Asian/Two or More Races):\n",
      "        💰 $50k-$75k | 🏷️ Tech Early Adopter/Social Cause\n",
      "      😍 Sentiment: 3.0/5  🔥 Share: 80%\n",
      "      💯 Credibility: 4.0/5  🛒 Purchase: 50%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As a person who values social change and benevolence, this campaign immediately ...\n",
      "\n",
      "   🗣️  James Running Bear (43-47, American Indian or Alaska Native):\n",
      "        💰 $25k-$50k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 4.0/5  🔥 Share: 85%\n",
      "      💯 Credibility: 4.0/5  🛒 Purchase: 65%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: As someone deeply rooted in community values and the importance of water within ...\n",
      "\n",
      "   🗣️  Elena Redbird (45-49, American Indian or Alaska Native):\n",
      "        💰 $25k-$50k | 🏷️ Social Cause\n",
      "      😍 Sentiment: 3.5/5  🔥 Share: 75%\n",
      "      💯 Credibility: 4.0/5  🛒 Purchase: 60%  ✅ Controversy: False\n",
      "      🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "      💡 Key insight: This message resonates strongly with my core values of community cohesion and be...\n",
      "\n",
      "   ✅ Collected 14 M2-enhanced reactions\n",
      "✅ Collected 14 M2-enhanced reactions\n",
      "\n",
      "📊 Stage E: Comprehensive M1/M2/M3 insight aggregation...\n",
      "\n",
      "📊 Aggregating M1/M2/M3 enhanced insights from 14 reactions...\n",
      "   ✅ Generated comprehensive M1/M2/M3 insights\n",
      "✅ M1/M2/M3 comprehensive insights generated\n",
      "\n",
      "🔍 Stage F: Setting up enhanced interactive exploration...\n",
      "✅ Explorer ready with M1/M2/M3 capabilities\n",
      "\n",
      "====================================================================================================\n",
      "                M1/M2/M3 ENHANCED SOCAIO ANALYSIS RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "📋 CAMPAIGN CONTEXT:\n",
      "   Company: international NGO (medium (100-500 employees))\n",
      "   Goal: viral awareness and action for clean water cause\n",
      "   Channel: social media platforms\n",
      "   Target outcome: viral sharing and donations\n",
      "\n",
      "📈 M2 ENHANCED OVERALL METRICS:\n",
      "   Sentiment: 3.32/5 (Very Positive 😍)\n",
      "   Share Likelihood: 79.3%\n",
      "   Credibility: 4.2/5\n",
      "   Purchase Intent: 64.6%\n",
      "   Top Emotions: trust(0.8), anticipation(0.7), joy(0.5)\n",
      "\n",
      "🎯 M1/M2 ENHANCED DEMOGRAPHIC INSIGHTS:\n",
      "\n",
      "   📌 Income Tiers:\n",
      "      😍 $25k-$50k:\n",
      "         📊 Sentiment: 3.6, Share: 82%, Credibility: 4.2/5, Purchase: 68%\n",
      "         🔥 Triggers: benevolence, community, social responsibility\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from $25k-$50k. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😍 $50k-$75k:\n",
      "         📊 Sentiment: 3.5, Share: 80%, Credibility: 4.2/5, Purchase: 57%\n",
      "         🔥 Triggers: benevolence, empathy, hope\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from $50k-$75k. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😊 $75k-$100k:\n",
      "         📊 Sentiment: 2.6, Share: 73%, Credibility: 4.3/5, Purchase: 68%\n",
      "         🔥 Triggers: community, benevolence, impact\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from $75k-$100k. High credibility (4.3/5). Amplify to similar audiences.\n",
      "      😍 $150k+:\n",
      "         📊 Sentiment: 3.5, Share: 80%, Credibility: 4.2/5, Purchase: 62%\n",
      "         🔥 Triggers: benevolence, community service\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from $150k+. High credibility (4.2/5). Amplify to similar audiences.\n",
      "\n",
      "   📌 Education Levels:\n",
      "      😍 Master's:\n",
      "         📊 Sentiment: 3.5, Share: 82%, Credibility: 4.3/5, Purchase: 63%\n",
      "         🔥 Triggers: benevolence, community engagement, empathy\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Master's. High credibility (4.3/5). Amplify to similar audiences.\n",
      "      😍 Bachelor's:\n",
      "         📊 Sentiment: 3.2, Share: 78%, Credibility: 4.2/5, Purchase: 65%\n",
      "         🔥 Triggers: benevolence, community, community service\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Bachelor's. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😍 Some College:\n",
      "         📊 Sentiment: 4.0, Share: 85%, Credibility: 4.0/5, Purchase: 65%\n",
      "         🔥 Triggers: community, tradition\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Some College. High credibility (4.0/5). Amplify to similar audiences.\n",
      "\n",
      "   📌 Brand Affinity:\n",
      "      😍 Social Cause:\n",
      "         📊 Sentiment: 3.3, Share: 79%, Credibility: 4.3/5, Purchase: 66%\n",
      "         🔥 Triggers: benevolence, community, hope\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Social Cause. High credibility (4.3/5). Amplify to similar audiences.\n",
      "      😍 Tech Early Adopter/Social Cause:\n",
      "         📊 Sentiment: 3.0, Share: 80%, Credibility: 4.0/5, Purchase: 50%\n",
      "         🔥 Triggers: benevolence, social change\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Tech Early Adopter/Social Cause. High credibility (4.0/5). Amplify to similar audiences.\n",
      "\n",
      "   📌 Political Lean:\n",
      "      😍 Liberal:\n",
      "         📊 Sentiment: 3.6, Share: 82%, Credibility: 4.3/5, Purchase: 68%\n",
      "         🔥 Triggers: benevolence, hope, community\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Liberal. High credibility (4.3/5). Amplify to similar audiences.\n",
      "      😊 Conservative:\n",
      "         📊 Sentiment: 2.2, Share: 75%, Credibility: 4.2/5, Purchase: 52%\n",
      "         🔥 Triggers: community, impact, benevolence\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Conservative. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😍 Moderate:\n",
      "         📊 Sentiment: 3.4, Share: 75%, Credibility: 4.1/5, Purchase: 64%\n",
      "         🔥 Triggers: benevolence, community service, community\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Moderate. High credibility (4.1/5). Amplify to similar audiences.\n",
      "\n",
      "   📌 Age Bands:\n",
      "      😍 23-27:\n",
      "         📊 Sentiment: 3.2, Share: 82%, Credibility: 4.2/5, Purchase: 62%\n",
      "         🔥 Triggers: benevolence, community engagement, empathy\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 23-27. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😊 35-50:\n",
      "         📊 Sentiment: 1.5, Share: 70%, Credibility: 4.5/5, Purchase: 55%\n",
      "         🔥 Triggers: community, impact\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 35-50. High credibility (4.5/5). Amplify to similar audiences.\n",
      "      😍 45-49:\n",
      "         📊 Sentiment: 3.2, Share: 70%, Credibility: 4.0/5, Purchase: 65%\n",
      "         🔥 Triggers: community, benevolence, community support\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 45-49. High credibility (4.0/5). Amplify to similar audiences.\n",
      "      😍 28-32:\n",
      "         📊 Sentiment: 3.6, Share: 81%, Credibility: 4.4/5, Purchase: 70%\n",
      "         🔥 Triggers: benevolence, hope, community\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 28-32. High credibility (4.4/5). Amplify to similar audiences.\n",
      "      😍 55-70:\n",
      "         📊 Sentiment: 3.5, Share: 80%, Credibility: 4.0/5, Purchase: 60%\n",
      "         🔥 Triggers: benevolence, community service\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 55-70. High credibility (4.0/5). Amplify to similar audiences.\n",
      "      😍 65-69:\n",
      "         📊 Sentiment: 3.5, Share: 80%, Credibility: 4.5/5, Purchase: 65%\n",
      "         🔥 Triggers: benevolence, community service\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 65-69. High credibility (4.5/5). Amplify to similar audiences.\n",
      "      😍 43-47:\n",
      "         📊 Sentiment: 4.0, Share: 85%, Credibility: 4.0/5, Purchase: 65%\n",
      "         🔥 Triggers: community, tradition\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from 43-47. High credibility (4.0/5). Amplify to similar audiences.\n",
      "\n",
      "   📌 Ethnicity (OMB):\n",
      "      😍 Asian:\n",
      "         📊 Sentiment: 3.3, Share: 82%, Credibility: 4.3/5, Purchase: 68%\n",
      "         🔥 Triggers: benevolence, community engagement, empathy\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Asian. High credibility (4.3/5). Amplify to similar audiences.\n",
      "      😊 Hispanic or Latino:\n",
      "         📊 Sentiment: 2.2, Share: 68%, Credibility: 4.2/5, Purchase: 62%\n",
      "         🔥 Triggers: community, impact, benevolence\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Hispanic or Latino. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😍 Black or African American:\n",
      "         📊 Sentiment: 3.9, Share: 82%, Credibility: 4.5/5, Purchase: 70%\n",
      "         🔥 Triggers: hope, community, benevolence\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Black or African American. High credibility (4.5/5). Amplify to similar audiences.\n",
      "      😍 White:\n",
      "         📊 Sentiment: 3.5, Share: 80%, Credibility: 4.2/5, Purchase: 62%\n",
      "         🔥 Triggers: benevolence, community service\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from White. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😍 Asian/Two or More Races:\n",
      "         📊 Sentiment: 3.0, Share: 80%, Credibility: 4.0/5, Purchase: 50%\n",
      "         🔥 Triggers: benevolence, social change\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Asian/Two or More Races. High credibility (4.0/5). Amplify to similar audiences.\n",
      "      😍 American Indian or Alaska Native:\n",
      "         📊 Sentiment: 3.8, Share: 80%, Credibility: 4.0/5, Purchase: 62%\n",
      "         🔥 Triggers: community, tradition, community support\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from American Indian or Alaska Native. High credibility (4.0/5). Amplify to similar audiences.\n",
      "\n",
      "   📌 Geography:\n",
      "      😍 Urban:\n",
      "         📊 Sentiment: 3.5, Share: 82%, Credibility: 4.3/5, Purchase: 66%\n",
      "         🔥 Triggers: benevolence, hope, community service\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Urban. High credibility (4.3/5). Amplify to similar audiences.\n",
      "      😊 Suburban:\n",
      "         📊 Sentiment: 2.2, Share: 68%, Credibility: 4.2/5, Purchase: 62%\n",
      "         🔥 Triggers: community, impact, benevolence\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Suburban. High credibility (4.2/5). Amplify to similar audiences.\n",
      "      😍 Rural:\n",
      "         📊 Sentiment: 3.8, Share: 80%, Credibility: 4.0/5, Purchase: 62%\n",
      "         🔥 Triggers: community, tradition, community support\n",
      "         🎭 Emotions: trust(0.8), anticipation(0.7)\n",
      "         💡 Strong positive response from Rural. High credibility (4.0/5). Amplify to similar audiences.\n",
      "\n",
      "⚠️  BIAS & DIVERSITY ANALYSIS:\n",
      "   Potential biases detected: Urban-centric focus, Digital divide\n",
      "   Diversity gaps: More emphasis needed on disability access, Consideration for non-English speaking audiences\n",
      "   Inclusivity score: 8.0/10\n",
      "\n",
      "🎭 EMOTIONAL THEMES:\n",
      "   • benevolence\n",
      "   • community\n",
      "   • hope\n",
      "   • community service\n",
      "   • social responsibility\n",
      "   • community engagement\n",
      "   • empathy\n",
      "\n",
      "📋 M1/M2/M3 STRATEGIC EXECUTIVE SUMMARY:\n",
      "**Strategic Executive Summary**\n",
      "\n",
      "**1. Overall Reception Analysis:**\n",
      "The campaign has generated a moderately positive reception, with an average sentiment score of 3.32 on a scale of -5 to +5. The credibility of the campaign is strong, averaging 4.2 out of 5, indicating that the messaging is trusted across various demographics. The average purchase intent, representing the likelihood of donations, stands at 64.6%. This suggests a favorable inclination towards supporting the cause, although there is room for improvement to enhance donation rates.\n",
      "\n",
      "**2. Key Demographic Patterns:**\n",
      "- **Income Tiers:** The $25k-$50k and $150k+ income brackets show higher sentiment and purchase intent, indicating these groups are more receptive to the campaign. The $75k-$100k group, however, exhibits lower sentiment, suggesting targeted engagement strategies may be needed.\n",
      "  \n",
      "- **Education Levels:** Individuals with some college education show the highest sentiment (4.0) and consistent credibility (4.0), indicating they are a key audience for engagement. Master's degree holders also show strong credibility (4.3) and purchase intent (63%).\n",
      "\n",
      "- **Brand Affinity:** Those with a social cause brand affinity display higher sentiment and credibility compared to tech early adopters. This highlights the importance of emphasizing the social impact of the campaign.\n",
      "\n",
      "**3. Emotional and Controversy Risk Assessment:**\n",
      "The campaign has a balanced emotional impact, with no significant controversy risks identified. The sentiment across political leanings, particularly among liberals, is positive, though conservatives show lower sentiment, indicating potential areas for message adjustment to enhance appeal.\n",
      "\n",
      "**4. M3 Simulation-Based Projections:**\n",
      "Simulations suggest high potential for virality, with an average share likelihood of 79.3%. This indicates that the campaign’s content is engaging and shareable. However, achieving consensus across all demographics may require tailored messaging to address varying sentiment levels, particularly in suburban and conservative audiences.\n",
      "\n",
      "**5. Specific Actionable Recommendations:**\n",
      "- **Enhance Messaging for Higher Income and Education Levels:** Tailor content to resonate with the $75k-$100k income group and those with higher education, emphasizing the impact of donations.\n",
      "  \n",
      "- **Increase Engagement with Conservative Audiences:** Develop messaging strategies that resonate with conservative values to improve sentiment and purchase intent.\n",
      "\n",
      "- **Leverage Social Cause Affinity:** Highlight the social impact and success stories to strengthen engagement with audiences already inclined towards social causes.\n",
      "\n",
      "- **Geographic Targeting:** Focus on urban and rural areas where sentiment and credibility are higher, while developing strategies to improve engagement in suburban areas.\n",
      "\n",
      "**6. Context-Specific Strategic Advice:**\n",
      "To optimize the campaign’s impact, it is crucial to maintain the current momentum on social media platforms by leveraging influencers and partnerships that align with the NGO’s values. Consider creating interactive content, such as challenges or user-generated content campaigns, to further boost virality. Additionally, continuous monitoring of audience feedback and sentiment will allow for agile adjustments to the campaign strategy, ensuring sustained engagement and increased donations.\n",
      "\n",
      "By implementing these strategic actions, the campaign can achieve its goals of viral awareness and increased donations for the clean water cause, ultimately contributing to the NGO's mission on a global scale.\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 4: Social Cause Campaign\n",
    "print(\"🌍 EXAMPLE 4: NGO Social Cause - Viral Call to Action\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_4 = socaio.run_full_pipeline(\n",
    "    message=example_message_4,\n",
    "    goal=\"viral awareness and action for clean water cause\",\n",
    "    channel=\"social media platforms\",\n",
    "    tone=\"urgent but hopeful\",\n",
    "    company_type=\"international NGO\",\n",
    "    company_size=\"medium (100-500 employees)\",\n",
    "    audience_size=\"global social media audience\",\n",
    "    brand_context=\"Established water access organization\",\n",
    "    campaign_type=\"social cause awareness\",\n",
    "    target_outcome=\"viral sharing and donations\",\n",
    "    personas_per_segment=2\n",
    ")\n",
    "\n",
    "socaio.display_results(results_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 5: Luxury Exclusivity Marketing\n",
    "print(\"💳 EXAMPLE 5: Luxury Financial Product - Ultra-Exclusive\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uncomment to run:\n",
    "# results_5 = socaio.run_full_pipeline(\n",
    "#     message=example_message_5,\n",
    "#     goal=\"attract ultra-high-net-worth individuals\",\n",
    "#     channel=\"exclusive marketing channels\",\n",
    "#     tone=\"sophisticated and exclusive\",\n",
    "#     company_type=\"premium financial services\",\n",
    "#     company_size=\"large financial institution\",\n",
    "#     audience_size=\"select high-income individuals\",\n",
    "#     brand_context=\"Ultra-premium credit card for wealthy elite\",\n",
    "#     campaign_type=\"luxury product marketing\",\n",
    "#     target_outcome=\"applications from qualified prospects\",\n",
    "#     personas_per_segment=2\n",
    "# )\n",
    "# \n",
    "# socaio.display_results(results_5)\n",
    "\n",
    "# Advanced Analysis Examples\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"💡 ADVANCED ANALYSIS FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(\"After running any example above, try these advanced features:\")\n",
    "print()\n",
    "print(\"# View detailed persona reactions:\")\n",
    "print(\"# results_1['explorer'].show_persona_details()\")\n",
    "print()\n",
    "print(\"# Visualize sentiment patterns:\")\n",
    "print(\"# results_1['explorer'].plot_sentiment_distribution()\")\n",
    "print(\"# results_1['explorer'].plot_share_likelihood()\")\n",
    "print()\n",
    "print(\"# Filter by demographics:\")\n",
    "print(\"# young_personas, young_reactions = results_1['explorer'].filter_by_demographic(age_range='18-30')\")\n",
    "print(\"# urban_personas, urban_reactions = results_1['explorer'].filter_by_demographic(location='urban')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Test with a policy announcement\n",
    "example_message_2 = \"\"\"\n",
    "NEW CITY POLICY: Effective January 1st, all downtown parking will transition to a dynamic pricing model. \n",
    "\n",
    "Peak hours (8am-6pm): $5/hour\n",
    "Off-peak hours: $2/hour\n",
    "Weekend rates: $3/hour\n",
    "\n",
    "This evidence-based approach will reduce traffic congestion and improve air quality while generating revenue for public transit improvements.\n",
    "\n",
    "Revenue will fund new bus routes and bike lanes. Learn more at CityParking.gov\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example message 2 (Policy Announcement):\")\n",
    "print(example_message_2)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Features Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of demographic filtering (uncomment after running analysis)\n",
    "# print(\"Filtering by young adults (18-30):\")\n",
    "# young_personas, young_reactions = results_1['explorer'].filter_by_demographic(age_range=\"18-30\")\n",
    "\n",
    "# print(\"\\nFiltering by urban locations:\")\n",
    "# urban_personas, urban_reactions = results_1['explorer'].filter_by_demographic(location=\"urban\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Custom Message Testing Area\n",
    "\n",
    "Use the cells below to test your own messages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your own message here\n",
    "your_message = \"\"\"\n",
    "Replace this with your message to test!\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment and modify to run your test\n",
    "# your_results = socaio.run_full_pipeline(\n",
    "#     message=your_message,\n",
    "#     goal=\"your campaign goal\",\n",
    "#     channel=\"your channel\",\n",
    "#     tone=\"your desired tone\",\n",
    "#     personas_per_segment=2\n",
    "# )\n",
    "\n",
    "# socaio.display_results(your_results)\n",
    "# your_results['explorer'].plot_sentiment_distribution()\n",
    "# your_results['explorer'].plot_share_likelihood()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fixed_ai_env",
   "language": "python",
   "name": "fixed_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
